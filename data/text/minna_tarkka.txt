It is true that communicative media already have established a continuity in time and space: telephone, fax, electronic mail, numerical and telematic networks, radio, television, the press, etc. This continuity is still not the continuity of the active and living thought, singular and differentiated, emergent and cohering everywhere, but rather a network for the transportation of information. Do the viewers of a televised transmission share a community? Do they bring together their experiences and their intellectual powers? Do they envisage and perfect new mental models of a situation together? Do they even exchange arguments? No. Their brains are not yet cooperating. The continuity effected by the media is only physical. It is a necessary prerequisite of the intellectual continuity but not sufficient in itself. Until this morning the work of writing was undoubtedly one of the most efficient means for the production of collective thought ever invented. The network of libraries keeps records of the creation and the experience of myriads of dead and living human beings. The fragile filament of memory is re-established, dormant thoughts revivified from generation to generation through the processes of reading and of interpreting. Translations from one language to another, or from one discipline to another, assure the communication between detached spaces of thought.
But by its nature the classical form of writing is a static and discontinuous system of signs. It is an inert, parcelled, dispersed body becoming more and more enormous each moment, and its unification and resuscitation requires that each individual sacrifice years and years to research, interpretation to the establishment of connections. As a remedy to the present situation, virtual worlds of collective intelligence will see the development of new forms of writing: animated pictograms, moving languages that will preserve traces of their interaction with navigators. By itself, the collective memory will organize itself, unfold itself anew for each navigator according to his interests and his previous traversings of the virtual world. The new space of signs will be sensitive, active, intelligent, at the service of its explorers. I ask again: what is interpretation? The subtle mind attempting to invite the inert body of letters into a dance.The evocation of the breath of the author in front of dead signs. The haphazard reconstruction of the knot of affects and of images in which the text originates. And, finally, the production of a new text, that of the interpreter. But what if the signs are alive? What if the image-text or the space-thought continuously grows, proliferates and metamorphoses itself to the beat of the collective intelligence? What if the leaden characters cede their place to some dynamic and translucent substance? What if the opacity of the gigantic stratifications of texts effaces itself in front of a flowing and continuous milieu the center of which is always occupied by its explorer? After the encounter between the vivifying spirit and the dead letter, after the dialectic of the corpus and the oral tradition, comes a new mode of the construction of the continuity of thought, a mode making possible the participation of everyone in the adventure of a nomadic language.

The first nomadic people followed after their flocks searching for nourishment, moving about following the rhytm of seasons and of rains. Today we are nomads following after the future of humanity, the future traversing us and made by us. The human being has become its own climate, an endless season with no return. We are hord and flock intermingled, more and more attached to our instruments and to the world moving with us, strolling on a new steppe each day. Neanderthal men, well adapted to the wonderful hunting expeditions on the glacial tundra, became extinct when the climate abruptly became warmer and more humid. Their natural game disappeared. Despite their intelligence these growling or mute men had no voice, no language with which to communicate with each other. Therefore the solutions found for their problems here and there could not be made more general. They remained dispersed even when they were faced by the transformation of the world surrounding them. They did not change with it. Today the homo sapiens is face to face with a fast modification of its surroundings, a transformation of which it is the collective involuntary agent. We may either cross a new threshold, a new stage in the evolution of man, by inventing some attribute of humanity as essential as language but on a superior level. Or we may continue to "communicate" through the media and to think in institutions detached from one another, organizing moreover the suffocation and division of intelligences. In the second case the only problems we would still be confronting would be problems of survival and of power. But if we were to take the route of the collective intelligence, we would gradually invent techniques, systems of signs, social forms of organization and of regulation permitting us to think together, to concentrate our intellectual and mental power, to multiply our imaginations and our experiences, to work out practical solutions for the complex problems affronting us in real time and on all levels. We would progressively learn to orientate ourselves in a new cosmos, constantly transforming itself and drifting, to become its authors as much as we can, to invent collectively ourselves as a species. Collective intelligence does not aim at the mastery of selves through human collectives but at an essential loosening of the grip changing the very conception of identity, the mechanisms of domination and of the breaking out of conflicts, the unblocking of confiscated communication, the mutual launching of isolated thoughts. So we are now in the same situation as a species whose each member would possess a good memory, would be perceptive and astute, but which would not yet have reached the stage of the collective intelligence of the culture because it would not have been capable of inventing an articulated language. How can one invent language if one has never spoken, if one's ancestors have never pronounced a single phrase, if one has no example to follow, not the slightest idea of what language could be? We are as nearly as possible in the same situation presently: we do not know what it is that we have to create, what we may already have obscurely began to envision. Still it only took a few millenia for the homo habilis to become the homo sapiens, to cross such an imposing threshold; it launched itself in the unknown, inventing the earth, the gods, and the endless world of signification. But languages are made for the "human scale" communication within small communities, perhaps even to guarantee the stability of their relations. Thanks to writing we have reached a new stage. The technique of writing effected the growth of the efficiency of communication and the organization of human groups; its scope was much wider than could ever have been that of shere speech. But this change took place at the expense of the unity of societies: it caused the division of societies into bureaucratic machineries for the handling and manipulation of information with the aid of writing and into those to be "administered". The task of the collective intelligence is to discover, or to invent, the other side of writing, the other side of language, so that the manipulation of information would be distributed everywhere, coordinated everywhere, that it would no longer be the priviledge of separate social organs but, on the contrary, would be naturally integrated into every human activity, as a tool in the hands of everyone. This new dimension of communication should evidently permit the mutuality of our knowledge and the reciprocality of its transmission which is the most rudimentary condition of the collective intelligence. In addition it would open up two major possibilities that would radically transform the fundamental facts of life within societies. First, we would have at our disposal simple and practical means of finding out what it is that we are doing together. Second, we could handle, even more easily than we write today, instruments allowing collective enunciation. And all of this no longer on the scale of paleolithic clans, or on that of States and historical institutions, but with the amplitude and velocity of gigantic turbulences, of deterritorialized processes, and of anthropological nomadism influencing us today. If our societies content themselves with mere intelligent government, they will almost certainly not attain to goals set by them. In order to have some chances of a better life, they will have to become intelligent by the masses. From beyond the media aerial machineries will make the voice of the multiplicity heard. It is still indiscernible, muffled by the mists of the future, bathing another kind of humanity in its murmur, but we are destined for an encounter with superlanguage.
The advantage on the other hand, is that these submicroscopic data can be transmitted without material movement in space and therefore without human accompaniment. Nontechnical media are bound to a physical carrier, they require the same network infrastructure as traffic of people and goods. The earliest wire networks had a point-to-point structure, requiring access points for in- and output, relay or refresher stations at regular intervals, and central nodes where messages are switched to their destination. In 1896, Marconi's wireless telegraphy extended the traffic of signals into the ethereal radio spectrum. The point-to-point cable was supplemented by omnipresent waves that can be intercepted by anyone owning a receiver. Radio extended the distance the voice carries virtually around the globe. With the broadcast networks of radio and TV, the center-to- all structure was invented. One speaks and all listen. These media are an extension of the public sphere, and therefore the radio spectrum is usually considered a public resource and regulated accordingly. Broadcast media create the masses they address,synchronizing millions of non-present, anonymous media recipients. McLuhan points to the origin of technical media in the medium print. In contrast to his own interpretation of the electronic media as fundamentally different from print, in their homogenizing function they are not. Reading this quote against its author, I see the program of 'homogenization of men and materials' rising to its ultimate violent power only in its military form under conditions of mass- mobilization during the Second World War (radio), and in its postwar civilian form under conditions of mass-markets, -media, -automobilization, -tourism etc. (TV). One further important aspect of technical media is that perception of the world shifted from the real thing to its stored mediatizations. Typists took dictation not from their superior's voice but from a gramophone or telegraphone recording. The question if Leland Stanford's horse had all four feet off the ground when in gallop could not be answered by observation through the naked eye, but Muybridge's serial photographs showed that it was in fact the case. The amount of live music we listen to is neglectable in comparison to prerecorded music. Whereas live broadcast implies a co-existence in time, a simultaneity that seems to warrant authenticity, much of what we see on TV is pre-recorded, edited, re-run - if we are not watching out of local storage of video anyway. Personal communication shifted from synchronous to asynchronous with the storage of answering machines, faxes, and email. The Matrix itself is a vast and rapidly growing-library. In short, large and exponentially growing parts of our media horizon are 'canned', and the two essential new operations besides transmission that technical media add to those of the Gutenberg Galaxy - copying and editing - are based on storage media.
The computer has its roots in mathematics which is indistinguishably linked to astronomy. Computing machines were built before Leibniz, like Schickhard's calculating clock (!) (1624) or Pascal's adding machine (1642). Still the primacy goes to Leibniz who produced a great confluence of streams of ideas, and contributed profoundly to symbolic logic, combinatorics, and therefore the history of the computer. Babbage should at least be mentioned in passing. His projected Analytical Engine was to have included most of the characteristics of modern computers realized only a hundred years later: a store, a mill (CPU), a transfer system, in- and output, and he also anticipated automatic operation, external data memories, conditional operations and programming. In 1847, Boole used a binary notation to represent truth-values in formal logic, 0 and 1 representing 'false' and 'true'. Shannon and Weaver's information theory translated the Boolean false and true into off and on states in electronic components. Signals, since this ultimate analytic cut with Ockham's razor, fall apart into basic indivisible yes/no units called bit. Like 'atom' for the material world and 'individuum' for society (both meaning 'indivisible'), 'bit' marks the smallest possible unit, the simplest building block of any possible symbolic system. Having mentioned some of the shoulders he was standing on, I can now turn to Alan Turing. I suggest to name the emerging horizon of binary digital media "Turing Galaxy", because its two central concepts were first formulated by him. One is the Universal Machine, the extremely primitive machine that can emulate any machine, the typewriter that reads and writes an operative text out of no more than two characters which freely models the appearance of the typewriter itself, the Universal Medium that precedes and empowers any possible multimedia to come. From then on every phenomenon and every process that can be described completely and unequivocally (the definition of both algorithm/automaton and the inter-subjectively scrutinizable knowledge of science) can be implemented in the one single machine to end all machines. The problem of building new machines has been replaced by the problem of writing an operational description of this new machine for the universal machine. (5) The other is the thought experiment known as the Turing Test which provided a comprehensive re-definition of man as a symbol processing system on a par with machines, and technically resolved the subjectivity problem. (6) Since then, 'intelligent' modelling, signal processing, and pattern recognition - so called thinking - has turned into a continuum across a range of possible technical or biological implementat ons. 'Mind' and machine have become interconnectable (if not interchangeable). Turing or bit media inherit properties from earlier media. They still operate largely in the mind-frame of the mathematical and the Gutenberg Galaxy. The most essential new operation introduced in the Turing Galaxy seems to me simulation. While models in the Gutenberg Galaxy become operational only after being read into and processed by the cortical CPU, models in the Turing Galaxy run inside a dynamic self-active technical medium. Bit words have the double function of addressing human readers as well as machines, i.e. themselves. Action unfolds and changes according to a script or in response to the action of the user and to its own results. Simulation allows to test hypotheses, to automatically control real life processes, and to construct alternate worlds. Today we observe the collapsing of all media into the universal medium computer. Turing media connect people, libraries, machines, and aartificial communicational entities. We are still exploring what the usage of computers in 'Turing mode' could mean. My suggestion: acting inside of media, and interacting with artificial agents.
form of computer games. Games are simulations. In the earliest form they simulate rules and strategies of board games. Later they simulate technical systems (notably with the military flight simulator reappearing as entertainment product), and social systems ( role playing games, SimCity etc.). In games (as in simulation) the computer takes on the function of agency, of a counter- player, an interlocutor, simulating dragons, enemy aliens, humans, governments, or simply fate. The computer also provides the playing-space into which the human player projects herself as a sprite, avatar, or persona, a marionette of herrself that she flies by the wire of the joystick. This is the first time not only the eye and ear, but the hand reaches through to the other side of the proverbial looking glass. With the emergence of data networks, games shifted from single-player stand-alone games to multi-player networked games or MUDs (Multi-User Dungeons/Dimensions). Here human others are re-introduced into the position of counter-player, next to and on a par with pieces of software simulating game characters. Originally games in the narrow sense of the word built around the sword-wielding-and-monster-slaying world of Dungeons & Dragons, MUDs are developing into common meeting grounds around diverse topics including professional conferencing facilities and educational institutions.
A typical host on the Matrix has a tree structure. It might be presented as a directory listing, menu, or in an index file pointing to the individual texts. One might browse or search by keywords with the search space inside one database, one host, or network-wide. At the final nodes of the tree one might find a text, in itself complete with author, pagination, footnotes, etc. The Gutenbergian resources on the Matrix are vast. Librarians were among the first to inhabit and develop it. Just a few examples are the US Library of Congress, including their Soviet and Vatican online archives, the Project Gutenberg, books.com, the first bookstore on the Net, magazines like Wired, and a sprouting new category of multimedia Metazines like the Electric Eclectic. Do people actually read books on the screen? Do they print them out? How are etexts used? The advantage of having reference books ready for automatic searches is obvious. Same for checking quotes in any sort of text. Maybe people will start to actually read electronic books when screens are light enough to hold, as pleasant to the eye and as 'interactive' as print on paper. Maybe people will have them rread to them by a voice synthesizer. Already now, the ASCII text is driving a Braille interface to allow blind people to read them. But rather than looking at the 'usage' of an individual text it is apparent that 'reading' will take on a different meaning when you imagine a library of 10,000 etexts in the form of a single text corpus available to you at any time. Even though somebody like Borges might be able to store a huge library in his memory and quote from it literally even after going blind, this is not given to most of us mortals. But thanks to the automatized external memory, we have random access to all the stored ideas. We can keyword search, browse with guaranteed serendipity effects, follow through on various threads, all the while creating hyperl inks on the go, leaving tracks inside the Gutenberg horizon that we can follow again next time we touch any of the texts. Every work (say Dante's Divine Comedy (8) appears in its own context, and in any other that we might create. All these operations could be done inside a library, but involving a lot more foot-work. The increased accessibility is already more than a quantitative difference. But what other automatic operations on texts may emerge, most of all what the new faculty of simulation will mean for writing/reading, ie. 'thinking' under conditions of the availability of the virtually complete library (Lyotard) in a dynamic format at the tick of a few keys, will have to be seen. If all these operations have to be done using raw Unix commands or exotic database query languages, the bookish Gutenbergian will likely not feel very at home. Luckily, there have emerged hypertext interfaces that make life a lot easier (World Wide Web under Mosaic). The reader/writer sees a text page complete with graphic design, that can be read like the page of a book. The reader can mouse-click his way around in the labyrinth of the global online library, make annotations, leave 'bookmarks' etc. A special feature is that the 'footnotes' to materials (text, image, sound, and video) outside the present text are active. By clicking on them, the corresponding file is retrieved across the Matrix, and presented immediately. All these are Gutenbergian operations, accelerated to the speed of electricity. Their model is the library.
The Letter. Postal mail is basically a point-to-point network, switched (sorted) at post offices, transported by diverse means of transportation. 'Snail Mail', as it is called in net.land, is usually private, to someone you know, but it can be extended to point-to-many. Mailing •lists exist also in RL for commercial, administrative or grass roots usage, but switching from traffic to transmission is more than a linear change. The Universal Network Medium adds the function of a reflector. A list server (like Majordomus) is an automatic forwarding program that sends every incoming message on to every subscriber, and drops it into his mailbox. Mailing lists can be unmoderated, ie. the information is provided as is, or moderated, ie. preprocessed by a wetware editor agent, which for certain purposes helps to raise the information-to-noise ratio significantly. Whether it holds together a professional special interest group, a hobby club or a speaker's ccorner - the mailing list constitutes a form of public. Electronic fora or bulletin boards - the metaphors reveal the heritage of earlier equivalents in public face-to-face real space. The most impressive are, without doubt, the Usenet newsgroups. Forming another network within the networks, the newsgroups permeate across Usenet, UUCP,Internet and selections also into the commercial networks. One does not subscribe to newsgroups, and the messages are not delivered to one's mailbox. They rather sit on one's local host to be read, browsed, participated in whenever one likes. Mailing lists and newsgroups constitute the basis for a written sense of community. In order to do so, they have to provide some form of space-time coordinates to anchor the social. The placement of a message in one electronic forum creates an unambiguous attribution in index space (an address). Their sequence creates a temporal order, a history of speech acts in which regulars build a sense of group identity. Fora are usually archived, so even though a message was deleted locally you can still look it up. FAQ (Frequently Asked Questions) documents are the collected common sense that is not the lowest common denominator, but common expertise. Like in every form of communal exchange, rules for accepted use and conduct (nettiquette), for the prevention of redundancy, various ideas on how to enforce these rules, etc. are negotiated on the go. Communicational conflicts are solved, of course, also within the interaction, but as a novelty there are technical solutions as well, e.g. the killfile, also sometimes referred to as 'the bozo filter', that locally tunes down or makes invisible unwanted traffic without having to have any censorship at source. Moderated newsgroups and mail- servers, like postal-based news-letters (or the xerox machine-borne mini-komi, as the Japanese call the genre) are already crossing over into publishing. These publications are in the Public Domain, and the moderators are most of the time volunteer editors. Unmoderated newsgroups are a running comment by Everybody attached to Everything. Large events like Tiananmen or the Gulf War, just as small events like a change in the design of Starship Enterprise bring forth their own forums. Strategies have evolved to prevent the slightest idea of censuring an unmoderated newsgroup. Any attempt at dominating or turning it into a PR device will cause a flood of flame - the power of the many.[9] They are specific, global, personal, and very powerful. And again, the total is more than the sum of its parts. MindVox offers many services, among them "a constantly growing library that chronicles the very inceptions of Cyberspace, with timeslices of systems dating all the way back to 1979 - the first bulletin boards ever to exist. "An orgiastic idea for any sociologist, media and market researcher, historian or linguist. The whole problem of sampling that is fundamental to every empirical social science evaporates when you can operate on the complete set. And it comes with a tool box that allows you to do searches, sorts, pattern recognition and other analysis automagically. Fractal algorithms are used to analyze huge amounts of earthquake data out of which it is otherwise very hard to make sense. What collective image might arise if you ran a similar chaotic pattern synthesizer on the subset of, say all utterances on the topic 'Internet' in unmoderated newsgroups, and how it changed over the years? The casual enquiry What's everybody talking about? will receive an unpredictable but mathematically precise answer. The idea of Man, Mina, Everybody, this collective chimera that broadcasting and marketing directors have in mind when they talk about 'the audience' and 'the consumer' - this non-entity will get a voice.
Radio. There were downloadable sound files on the Internet before, but the first regular radio station in cyberspace was pioneered by Carl Malamud in March 1993. You can receive Internet Talk Radio on your desktop or laptop radio either 'live' or 'on tape'. ITR publishes from 30 to 90 minutes of professionally produced radio programming per day. It reaches 100,000 people in 30 countries. TV. Malamud did not choose a TV metaphor, simply because it requires more bandwidth than the majority of the Matrix population has available right now. Also, production of video information still requires an order-of-magnitude larger investment in facilities. As a first step towards general use MIME allows to include little video and sound blips in email. Not yet live broadcast of concerts, but downloadable video clips one finds at mtv.com. Adam Curry, former star host of MTV Networks and net.veteran, created a multimedia site in 1993 that now attracts an average of 35,000 people daily, including music industry professionals. The cable TV on the Internet is the Multicasting Backbone or in short M-Bone. Multicast is a continuous stream of video and audio data packets running over a virtual network layered on top of portions of the physical Internet. It combines a global point-to-point structure with local 'narrowcasting' to everyone who is tuned in. What's on the digital tube? If you belong to the lucky group of power networkers you can watch keynote speeches by John Perry Barlow, co-founder of the EFF, or Vinton G. Cerf, president of the Internet Society, live multicasts from the deep-sea or outer space, footage from NASA satellites and telescopes, eg. Keck, the world's largest pair of binoculars in the solar system. The M-Bone has even emerged a solution to the hotly debated '500 TV channel' problem: 'sd' or session directory is a TV guide where all ongoing events are announced and can be joined on mouse-click. CU-SeeMe, an offshoot of the M-Bone for personal computers, was first developed as a TV metaphor for live video, only later voice was added. Latest news while I am writing this: "Coming Soon - Newscasts on Your PC. Intel and CNN have teamed up to test 'LAN TV' , a system that turns a regular broadcast TV signal into a compressed digital data stream, capable of being received on regular 486-type desktop PCs. While Intel tests the technology, CNN will concentrate on determining what it is people want to watch on their computers, in order to develop a special corporate news service."(10) As with desktop print and radio, desktop TV is not restricted to corporate providers. A CCD camera, a VCR, a video-capture board, and some editing software allow, in principle, TV production and multicasting on every PC. After the telephone answering machine made everyone a radio announcer, the desktop multimedia answering machine will turn everyone or his agent into a celebrity TV announcer. The Hunt. It is here that we see the Dungeon Masters and the Net-Gods at play. The Hunt is a kind of paper-chase, only without the paper. A game to encourage the players to "explore the Net, and traverse little known routes." Huntmaster Rick Gates, Student & Lecturer of the University of Arizona, got the idea "sometime in 1991 when I began to realize the enormous variety and volume of information available via what I will call the Net (Bitnet, Usenet, The Internet, etc.). [...] I suppose my initial ideas were based on the type of search exam that most library-school students have to go through during a class in Basic Reference.' Some of us enjoyed this type of challenge; we called it 'The Thrill of the Hunt". (11) The Hunt is edutainment at its best, "casual instruction in training for information resources. [...] It provides for training in context, which for most people works better than books or chalk on a board." For beginning net.citizens it provides a chance to look over the shoulders of media-literate experts. "It helps more novice users, or Net 'settlers', understand how to move around using the 'trails' that the more experienced Hunt players have 'blazed'. [...] Learning how to learn is critical, and this only comes from experience."
cky part, as always with Oracles, is to formulated the right search command. (12) At the risk of boring you by repeating myself: old media don't go away, they are the content of the new ones, transformed into metaphors. If the 'content' of the Net is magazines, radio, TV etc., then the 'content' of those is the Net. The whole Net is abuzz with questions of where it is heading. Self- reflectiveness is part of the constitution of a new medium. But this is a transient stage. As with Usenet newsgroups we will see that the early bias towards computing and networking itself will shift. Today the comp. groups are far outnumbered by the alt. and rec. groups. There are, of course, differences between the Meta-Medium and the other media it embraces. With text, sound and video editing capabilities on personal computers getting cheaper, one-person desktop publishing and multicasting houses become possible. This was also said when xerox machines spread, and again with laser printers . It did indeed happen to some degree, but it also showed that not everybody has the urge to publish. Most of all, cheap high-quality printing on a laser engine did not solve the problem of distributing and making your product known. This changes with the Universal Medium that is production, transmission and reception medium in one. To multicast does not require the concentration of capital and power necessary to produce a full daily broadcast schedule in one of The Networks. Anybody who finds a friendly host or scrapes up a few thousand dollars to set up her own can be media provider. Combining broadcast tools and communications networks, and private and various forms of public communications, makes all the difference. The implications for the changing nature of work become visible already. Everybody who offers informational products or services can do so - globally, from anywhere, at a price that a private person can afford. This is not to say that capitalism will crumble, and give way to an Anarchist's dream of self-expression for everyone. But it does mean the end of capitalism as we know it. People who are part of what is often called a revolution are very excited about the empowering qualities of the Net.
The oldest medium holds its entrée as the latest, the get-together. The basic social function of going somewhere and hanging out with friends and like-minded people requires a common place and time. While tree-shaped lists, keywords and hyperlinks are appropriate for retrieving data, 'human information' needs conversational tools, an anthropomorphic space not to consult repositories of passive information, but to meet people. Today the theater metaphor (Laurel) re-emerges and with it the idea of actors and agents (Brooks, Maes). It is here that we re-encounter the ars memoria. Cicero suggested to use personae for the memory image that anchors the 'things'. Yates' characterization of a classic memory image: consists of human figures, is active, dramatic, striking, under circumstances that recall the 'whole' thing, can be read directly parallel to Laurel's explications of a desirable human-computer interface. What is not lost in the transition from the art of memory to the art of interface design is most of all the dimension of mental space. The stage where the play is enacted is idea space, regardless whether the mental image is evoked by printed, pictorial or sound signs, or a Wagnerian multimedia Gesamtkunstwerk. An important difference between the two arts isthat the mental space of the ars memoria was not shared. An orator would, of course, share his idea space with his audience, but as he walked around the chambers of his memory, picking the points he wanted to touch upon from the statues where he had deposited them, he was alone. He would never encounter an other there. Net.operations in Gutenberg mode are mostly silent, ASCII, solitary, and asynchronous. Most of the time the netsurfer is not aware of others who 'are inside' the same host. While we have seen that newsgroups can turn into a home on the Net, the potential of the Universal Machine is by no means eexhausted there. The silent and iconoclast world is enlivened by the beginning multimediatization. But hypertext, radio and TV metaphor are precisely that, like horse-less carriage and wire-less radio we now have paper-less libraries and station-less massmedia. They are metaphors for different media, not for the market square in the Global Village (McLuhan). A different approach that does not come from Gutenberg (although it is not illiterate), nor from mathematics, and not from the technical network media, but from game are MUDs. According to one definition they are "detailed and realistic multi-player simulations that present ongoing campaigns and universes with evolving storylines, political systems, and landscapes being imagined into existence as play progresses." MUDs are shared places. You 'telnet' yourself there. Others 'are"there' as well, synchronously, even though from different 'real' time zones. From the theater metaphor we pick up the performing arts and the stage effects. From game/play we get the participatory elements and the challenge for the price at stake: recognition for wit, excellence, style, integrative qualities, for the craziness of thinking up something that nobody has ever done before.
In the Matrix also the physical body has no significance (except for the wetware break). But the mental body can travel along the wires and be re- incarnated in a remote Doppelganger. The same body can be played by a human, just as well as by the machine. On the behavior of human players there is much to be said and studied. Here I would rather take a closer look at the non-human players. Automatons and the game between man and machine carried tremendous fascination ever-since the days of the Ancients, with new boosts during the Renaissance (Maillardet's Magician, Vaucanson's Writer, etc.) and the industrial age. They were only sophisticated toys, but they triggered a philosopher like Descartes to think up a Turing Test avant la lettre. The philosophical and literary (eg. E.T.A. Hoffman) theme continues to fascinate mankind's phantasy. But it was only with Alan Turing and his influence on von Neumann, the cybernetics group, and others that a whole wave of mind-mirroring in Al, neuro nets, piano-playing robots and 'thinking machines' was triggered. This conceptual shift dismissed philosophy and literature, and made the Turing Testable machine the goal of a concrete effort of exact sciences. The first program that passed the Turing Test in a life-like situation was Weizenbaum's Eliza. Since then the Turing horizon has become populated by hosts of talkative and zealous homunculi, women, and daemons. One forum where the best of them come together is the Loebner Turing- Test competition, conducted annually since 1991. The New York business man has donated $100,000 prize money for a program that can pass as human in an unrestricted typed tele-conversation. Entries so far are required to be conversant - in "natural American English" - on one topic only. Entrants may selecttheir own topic areas, but the domains of knowledge must be "within the experience of ordinary people. One of the participants is Julia, a Maas-Neotek bot with an Al engine written by Michael Mauldin at Carnegie Mellon behind it. Between Loebner Turing Tests she logs onto a MUD and behaves like a regular player. She can be summoned, gives useful information, delivers mud.mai I messages to other players who are not currently logged in, dispenses witty quotes, can be nice to you, and kills you when teased too much - and next time you talk to her she will still be angry with you, because she even remembers.
It is envisaged that intelligent robots of the next generation be equipped with various sophistciated capabilities endowing them with desires and intentions, enabling them to perform hypothetical and defeasible reasoning, to solve problems creatively, to appreciate works of art, to achieve some form of cyberpleasure, etc. Understanding and the ability to develop explanations for observations and facts are fundamental for the realization of these capabilities. In fact explanation and understanding are 'two sides of the same coin' in both art and science. Our objective is to highlight techniques used in Artificial Intelligence which could provide mechanisms for modeling the aesthetic response of an intelligent robot, based on the causal explainability of complexity manifested in media such as electronic art. Leyton argues that art is related to explanation, in particular that the aesthetic response is the mind's evaluation of causal explanation. He maintains that the level of aesthetic response to art works is proportional to the level of complexity that an individual observes. He goes further arguing that the desire for art works is part of a general desire that the human mind has for complexity. Barratt also claims that humans seek to explicate complexity, and since the brain is finite, there must be a maximum degree of complexity that the mind is capable of explaining at any one time. If the degree of complexity is increased past this level, it exceeds the mind's capacity to explain it, artistic chaos is reached and consequently the viewer deems the art work to be incoherent. He concludes that the limit is set by the ability to give causal explanation, it is not complexity that is appetitive, but causal explanation itself. Clearly, if our aim is to develop intelligent robots with truly human-like characteristics, then they must be capable of artistic appreciation. For electronic art, appreciation must occur at the conceptual level and not at the physical (pixel) level. In the area of Artificial Intelligence the notion of explanation has been well explored. The complexity of explanations is often a reflection of the richness of the agent's background knowledge, and its ability to discern its surrounding world. Indeed, the aesthetic response to artistic chaos is equivalent to an explanation of a contradiction. Central to such an explanatory capability is the need for mechanisms supporting the modification or revision of knowledge, that is, learning. Belief revision models the process of accepting new information in such a way that an intelligent agent's epistemic state remains logically consistent, or coherent. Frameworks for explanation within the area of Artificial Intelligence can be used to support the aesthetic response of an intelligent agent. In particular, two important parameters of an explanation may assist in gauging an aesthetic response, namely the plausibility and the specificity of the explanation. In summary, if aesthetic response is the evaluation of causal explanation, then we can endow an intelligent robot with aesthetic responses which ebb and flow in accordance with the complexity of the causal explanation achieved.
I have always thought of computers as dynamic tools for introspection, exploration and discovery. Computer programming is instrumental in the externalization of ideas and algorithms are formal descriptions of what one hypothesis constitute the production of creative statements. The computer is a playground to speculate on the generative potential of ideas. As a matter of fact, the physical, tangible management of purely conceptual constructs becomes possible. However, the paradox is that while algorithmic specification allows the artist to touch the essence of his ideas it also creates a distance since all specification is indirect and seems to exclude spontaneous action. The idea is to view computers as partners in the process of creative decision-making. By way of algorithms we can explore various man- machine relations in this partnership: from studying total autonomy in computer programs to systems designed for expl icit interaction. The development of personal algorithms is the key to exploration and the gradual specification of objectives from incomplete knowledge, in sharp contrast to view the computer as slave, as a medium for deterministic visualization. I have characterized the interactive method where man and machine collaborate in a common effort and with common objectives as conceptual navigation; the artist-programmer gets feedback, his expectations are confirmed or contradicted by the program's behavior. Eventually, unexpected results may signal new and promising routes exposing unknown territories. Thus, man and machine contribute both to the creation of a computational climate that favours invention and to the development of a critical attitude towards the often complex relationships between programmed intention and actual result.
Writing algorithms has also forced me to evaluate experience vs. speculation. If one relies on models that have proven to be successful in the past, one 60 confirms what is already known. Algorithms that use rules reflecting this knowledge produce predictable results. Otherwise, designing processeswith the greatest possible freedom in pure speculation is like working outside of any known context making evaluation very hard indeed. The creation of new contexts for growing algorithmic activity mixing memories of the past and an open imagination is, I think, perhaps the most interesting challenge to algorithmic art.
Almost as if by magic - whatever procedure you dream of - you can probably extend the power of your dream to the computer and let it develop the dream beyond your wildest expectations. You may identify procedures for improvising with color, scale, and position - which is what artists have always done. Given sufficient definition you could develop a form generator and from your new vantage point see new possibilities for further elaboration on your routine. Through trial and error - interacting with the algorithm itself you proceed further into the new frontier. So what can we learn from this? We learn what artists have always known - that "CAD" programs, paint brush programs, paint brushes and drawing paraphernalia do not make art. Neither do artists or designers simply "make art". The one over-riding essential element to the process, "a developed artistic procedure", is necessarily unique for each artist and for each work of art. The procedure addresses a singular conjunction of elements for which there is no "universal" rule. The "calculus of form" may be placed in the service of such procedures but should not be confused with the art-making procedure. For the artist who writes the code the artistic procedure is the act of "writing the code", pretty much like the creative work of the composer when the composer writes a musical score. Making art does indeed require a "calculus of form". But the artist's instructions on how to employ the "calculus of form" precede the "calculus". One needs an "artistic procedure" which addresses the entire complex of elements for each specific work. The final form, unique and specific to each work, embraces more than the "calculus". While it embraces and grows from a "calculus" it might employ any of an infinite number of approaches to deliver the form. These may include metaphor, improvisations of the form phenomenon in and of itself, or reference to some other phenomenon or idea - historical, literary, political, mathematical or philosophic. Can an artist write an algorithm then for an artistic procedure? Emphatically yes! Such algorithms provide the artist with self-organizing form generators which manifest his or her own artistic concerns and interests. We are looking to an interesting time ahead of us when artists will be able to exchange and interact with each other's form-generating tools in ways we never dreamed. There are procedures yet to be developed to make this kind of interactive expression accessible - a time ahead when we will literally see an evolution of form including a genealogy associated with its creators.

Despite, or perhaps because of, a healthy skepticism, Artificial Intelligence (Al) has been making quiet progress in electronic arts. Artificial Intelligence has inspired traditional fields of electronic arts as well as it has developed new horizons for many artists working in electronic composition environments. Building on the success and shortcomings of previous experiences with computers in arts, the attempt to extend the paradigm of artificial intelligence systemsto the domain of electronic sonic arts is made now. Musicians are increasingly using intelligent machines to deal with tasks for which they are better equipped than humans. Computers are increasingly being used to address the brain-numbing complexity of modern electronic music products and processes, thereby allowing people to concentrate on their music and ideas. Expert systems, for example, help people by searching a book of rules to decide what to do in a particular situation; as machines do not forget, these systems can manage rules more consistently than people. Some musicians are using neural nets, which can recognize complex patterns, to apply precedents that are difficult to express in numbers or words. The real challenge facing technology is to recognize the uniqueness of machine intelligence and learn to work with it. Given enough memory, a computer can remember everything that ever happened to it or to anyone else. Furthermore, when faced with a logical problem or a theoretical model of how compositions or sounds should be, computers can deduce more results more quicklythan humans. Their complementary strengths should allow man and computer to work together and do things that neither can do separately.
Whereas the impossibility of physical death in cyberspace is one of its main attractions (certainly for the flight simulators used by the military), this absence of death and of death's possibility does not emasculate the project. For death becomes the ultimate ground for the cybernaught, not in terms of individual death, nor even death of the planet, but according to Lyotard, in the death of the solar system. On a number of occasions Lyotard mentions the inevitalbe the destruction of the solar system estimated to occur in 4.5 billion solar years. The task of technology, is to create an alternate non organic system that will survive this catastrophe. Not only does the certainty of this event constitute perhaps the most sublime of deaths, but the end of the solar system represents a finality, a resolution, that puts ultimate limits on human endeavour. Such closure however, comes at the end of a narrative space in which all the utopian and apocalyptic concerns that have defined twentieth century culture's relationship to technology, are able to play out their fictions. As a way of representing the body in space, according to a perspective that the logocentric apparatus has inherited form the renaissance, futurity is also associated with frontality, and opposed to anteriority. As a radiant, or irradiated subject, the cybernaught may transmit from a centre in all directions, nonetheless s/he is literally always looking in front. In front - to the absence of distance between the organic eye and the simulated scene, to the absence of difference between the real and the repesentation, to the unfolding in sequence of the virtual narrative, and to the future as a narrative of progress. This future space thus stands in for all the physical spaces which go missing in virtual worlds, and this future death defers the resolution of corporeality and the promise of transcendence that individual death promises. More than this, the future impossibility of organic embodiment provides the ultimate rationale for the numerical constitution, Cartesian co-ordination, and digital storage of the subject, who then shines with the necessity of survival. This is the radiant subject of art - the channel to the sublime, now irradiated. The subject who shares with radiant sound, the security of identity with the eventfullness, change and flux of the event. As Baudrillard says, we no longer need the VR glove or suit because 'we have swallowed our microphones' and 'internalized our aesthetic image.' 28 We have become the post holocaust meaning of radiant sound - transmissive but rotten at the core. And the realization of this subjectivity occurs, not at the point of solar explosion as radiance would suggest, but at the point of total computation. At this point, the signal continues to survive in outer space; the space of the future, but sound, and any vibrational body, is immediately extinguished by silence.
My first visit to virtual reality— a cartoon-like 'Virtual Seattle' at VPL Labs in California a number of years ago—indicated that for me at least, the great attraction was not the lure of computer technology or of interface devices, which included a cumbersome helmet ('eyephones') which put little video monitors over my eyes; and, the coarsely rendered, neon-colored artificial world, in which I had the illusion of being immersed was not a convincing imitation of the physical Seattle, or for that matter, any other landscape which could possibly have drawn me in. The allure of this cyberscape was the impression that it was responsive to me, as if my gaze itself was creating (or performing) this world and that I was to some extent enunciating it according to my own desire. My most abiding memory was of exhilarating ability to fly through the artificial world at great speed simply by cocking my hand like a gun—'navigation' is a poor term for this experience. Best of all, I had a sense of the weightlessness and super-power that I had imagined in childhood and had read about in myths and comic books, but had never before experienced, not even in my dreams. (My childhood friends in first and second grade and I tried fruitlessly to fly day after day by flapping blankets while jumping off walls and out of trees.) It is this feeling of transcendence of the mortal body and the gravity of earth that for me is a key to the desire and media attention which has been focused on 'cyberspace' and the subculture which has grown up around it.
The primordial virtual space is an utterly empty display, unlike the physical world, which is always 'full' and readymade. So far at least, cyberspace worlds are sparsely stocked with metaphors, now largely constituted from scratch with considerable graphic effort. Once these graphics are out of sight, it is easy to get lost in a void that is uniformly colored (usually black) and that wears infinity at its edges if not at a vanishing point. My first flight revealed Virtual Seattle, like most other virtual environments, to be relatively void but for a crude symbolscape of geometric objects. I remember my panic at flying through and out the swimming-pool-like image-space of Puget Sound and getting lost in utter emptiness. (I have also flown too far from the landingstrip metaphor of a Wall Street stock market program and have fallen off the checker-board world of 'Dactyl Nightmare.' The stock market program has an arrow function which points the way back to civilization.) What a comfort it was to find the traces of the human imagination in the spacescape near me again. On the other hand, why are these cyber-traces, the externalized imagination of electronic producers, filled with so little of our cultural legacy? I am thinking of metaphorically and graphically impoverished architectural flythroughs or crude male-centered fantasies of pornotopia ('Virtual Valerie') or a pseudo-prehistoric past wherein the only activity is relentless killing, (for instance, the aforementioned 'Dactyl Nightmare.') One task of art that commodity culture apparently eschews is to resituate the disengaged space of virtuality into a socio-historical context. For instance, Jeffrey Shaw's interactive city installations, such as virtual New York or Amsterdam, are richly symbolic, suggesting how the built environment may be refigured in a image-space as a kind of alphabet. Multiple and interlacing historical narratives are traced in a kind of writing motion over the display area via a bicycle interface. The Biblical reference in Shaw's piece at ars electronics 94, The Golden Calf, made what was otherwise a clever piece—a statue visible only through a mirror-like electronic display—into a commentary on electronic art itself. The uncanny and more sinister implications of my first flight occured to me later: A virtual space it is not just the ground or background or the landscape at which I look, or even that my look calls forth—that space looks at me, following my every move. Indeed, space constituted itself in response to various indices of my intention, for instance, the vectors of my gaze and the motion of my body or head. That is, in a virtual world, not just objects but space itself is interactive. As a consequence the virtual environment that surrounds the visitor itself can appear to be something 'live' or animate, 'that we cannot acknowledge as subject or persona in the traditional european sense, and which nonetheless constantly demonstrates that it sees us without revealing itself.
Of the many artistic responses to the Gulf War, I remember Frances Dyson's and Doug Kahn's sound and sculptural installation for its condensation of the sounds and images of birds in flight with the resonances of the air-war on Iraq. A more recent installation by Laura Kurgan explores the actual operation of several satellites in Global Positioning System or GPS by using them to trace the position of the New Museum gallery in New York. The installation was effectively demystifying, not only in revealing how this surveillance system works, but its material fallibility resulted in wavy deviations from geometric accuracy. Julia Scher has explored the psychical and cultural implications of electronic and computer surveillance in work spanning over a decade, including her 1993 installation, Predictive Engineering, at the San Francisco Museum of Modern Art, mixing live and recorded video on a two chiastically arranged and elegantly situated surveillance camera and monitor set-ups. The interest of art then may not be in the seamless operation of electronic culture nor in the production of realistic virtual worlds—like Icarus, that may be flying so low as to be dragged into the sea. The often mentioned desire for photographic resolution in virtual displays may also have as much to do with the goal of controlling physical objects and events as it does with aesthetics. An art of virtual spaces which simply aims toward realism of fit or of appearance with a physical landscape may then risk merely serving the instrumental or hegemonic purposes of military and business interests in an information society. On the other hand, art that surrenders to the allure of the mysterious or that seems to offer transcendence may find the wax that holds its feathers together melted by the sun. Exploiting the magical aura of virtual spaces risks satisfying the commodity and entertainment functions of information and nothing more. For, unlike prior illusion- producing modes, cyberspace is a means of enchanting not only liminal realms, but everyday reality. Even though it is has been discredited as a popular rather than scientific term, 'cyberspace' is appropriately built on the analogy of Norbert Wiener's cybernetics, or the study of feedback systems. In computers, feedback is elaborated into a programmed responsiveness which Sherry Turkle has noted, can captivate the user as a kind of 'second self'.2 But feedback is not restricted to the space of the monitor, for material artifacts and even a physical space itself can be 'cyberized,' or granted agency by programming it to simulate some form of human interaction, in the process ultimately lending it qualities associated with human personality. As Jay David Bolter, explains in Writing Space: The Computer, Hypertext and the History of Writing,' 'Artificial intelligence leads almost inexorably to a kind of animism, in which every technological device (computers, telephones, wristwatches, automobiles, washing machines) writes and in which everything that reads and writes also has a mind.' One futuristic vision of the personified or smart home proclaims, 'Once your house can talk to you, you may never feel alone again,14 suggesting this animism and a quasi-subjecthood can extend to even physical space, once it has been 'cyberized.' A utopia of ubiquitous computing would enchant the entire world, distributing magical powers to the most mundane aspects of existence.
Of course, business interests are far more concerned with 'information' as a resource and an exchange value, than with virtual environments, even 'smart houses' per se. 'Information' is knowledge decontextualized and stored as data (that is, as virtual objects.) In order to be retrieved and placed in a new context, that data must take on symbolic or metaphoric form in an interactive and to some degree immersive display. The value of information is realized not just in any one state, but as a passage from the conceptual to the virtual to the material and back again, crossing through a variety of reality statuses. For instance, virtual money or credit demands a passage through material objects in order to increase itself as interest. Jeff Schulz, for instance, has made the credit system the material of his performance art and of commentary in his essay, 'Virtu-Real Space: Information Technologies and the Politics of Consciousness:15 If virtual environments are best understood in connection with other social and cultural processes, as one stage in the unfolding of metaphors across a variety of reality-statuses and degrees of materiality, this suggests that the electronic arts are themselves part of a range or spectrum of interactive and immersive media and are not well-served by isolating them from art using other media, that is also concerned with the transformation of information societies into electronic culture. Artists from the ex-Eastern block or what was once the Third World are likely to suffer the consequences of this global change, even if they are excluded from its benefits. That is, there are artistic issues and perspectives which have a bearing on the global economic and cultural transformation we are undergoing that may be posed by those who have little access to computers or even to electricity —they must be welcomed into the discourse as full partners. Artists and cultural activists—for instance, Paper Tiger/Deep Dish and Ponton—have also not forgotten the issue of public access to the material and technical level where information is processed, stored and transmitted. It is real estate in terms of data space on computer disks and in main-frames, personal space in seats in front of computer work- stations, frequencies on the broadcast spectrum, satellite space off which to bounce signals, and room in the bandwidth of fiberoptic cables that global corporations struggle among themselves to own and control. The scarcity and costliness of these material gates of entry limit the number and types of subjects we can find in the virtual gathering spaces of an electronic culture. What we to some extent have and need more of is art which figures relationships between the virtual and the physical world, which demystifies the relation of the body to the virtual environment, and which is both a meta-commentary and an aesthetic statement. On the other hand, the technological ability to recreate the acoustic space of a medieval cathedral in one's living room, or to merge movie stars and tourists into the same image and have them interact, merely exploits the ability to superimpose the virtual over physical space: it is entertainment. The following section concludes by making some generalizations about virtual environments as virtual space, based in reflections on experience in cyberspace, from virtual realities to CD Rom work-stations to electronic networks.
The very idea of space becomes self-contradictory, when it is applied to virtual realms, especially the maze-like vectors and links which compose the paradoxical 'space' of networks. Virtual space is not so much space as 'nonspace,' for it need not occupy ground, nor be a continuous linear extension, area or void, nor even constitute the interval between things; and, unlike the material Lebensraum of earth, it not be perceived as limited or scarce. If the virtual space in question is the discontinuous, yet communal space of isolated computer network users, it can expand ad infinitum, like the text-based 'rooms' which make up a M.U.D. or multi-user dimension. But where is that noplace in which, for instance, two people talking by telephone meet? Where is the room and where is the display in which the hundreds who belong to the same M.U.D. (Multi-User Dungeon or Dimension) or M.O.O. (M.U.D., Object- Oriented) may gather? The reality-status of any one virtual environment is also unclear, seemingly in-between an exteriorized mental space, the apparatus of the image-display and the material world. The many different levels and degrees of virtuality in an information society add complexity to mystery. What, for instance, is the 'space' of a virtual object in a computer program? Even if it can be quantified as data in megabytes or ultimately in bandwidth or pixels, a virtual object itself remains an imperceptible potentiality, which occupies no space at all until it is accessed and displayed. Can one even say the object is 'inside' the opaque casing of the computer or hidden under the obscure machine language of programming?' Even if one could break into the black box or extract and analyze the program, one wouldnUt expose the virtual object, only the mechanism that has the potential to produce it. Yet, the virtual space on display is still a realm of cause-and-effect, though the consequences of any one action may seem more magical than logical, for they need not be proportionate to the results to which we are accustomed in physical space. Space is ordinarily conceived of as continuous or at least, at its most abstract, as a homogenous void. Yet, virtual non-space or cyberspace can be distributed discontinuously over physical space (in a way that is usually imagined as supported by ubiquitous computing.) Furthermore, physical separation between the users and objects of physical space need has little bearing on the seams which separate and link virtual spaces. What remains somewhat clumsy are the figural conventions which ease the passages between virtual 'worlds': the vortex, the window and the door are given too much work to do as metaphorical thresholds and passageways. The additive aesthetic principle of the Internet, the global network of networks, is an extremely elegant, non-hierarchical, rhizomatic global web of relatively independent yet connecting nodes. Though it was conceived out of militaristic considerations, it might be compared with Panofsky's analysis of the gothic cathedral. This comparison is not trivial, for combined as an infrastructural and virtual entity, the Internet is among the greatest architecture the world has every known, far greater than the material reference point of the information highway metaphor, the freeway system.
Such compression of space and time finds an exponent in Jeffrey ShawUs interactive installation, Revolution. The user's effort turns a grindstone interface, which churns out pictorial representations of hundreds of social revolutions in the historical record onto a video monitor. Revolution is then not a representational space of linear histories or of geographical areas but the presentational space of a metaphor and its recurring metahistorical patterns. The visitor to the installation stands for the protagonist and motive force of this social phenomenon, a spontaneously acting group called at times the 'mass,' the 'crowd' or the 'people.' Then the vocation of an art of the kind that reflects on electronic crowds and networks is not the representation of the visible world, but the visualization of what is otherwise inaccessible to perception and is difficult to imagine because of its scale, its discontinuity in space and or time or its impenetrability—from the insides of the body, the atom, or the black box to the outside of our galaxy and our universe. All the linking devices which create virtual spaces of greater and greater, albeit ephemeral unities—text-based networks, MUDUs and MOOUs, telecommunication satellite links and cables, but also protocyberspace like the nets which unify physical space—railroads and highways are understood, paradoxically enough as 'spaces.' Such virtual environments of discontinuous and overlapping jurisdictions would tax any political imagination capable of ethnic cleansing or of resolving ethnic conflict by dedicating bounded areas to one homogeneous culture. If virtual space were our model of political space, there would be no struggle for nationhood as a geographical entity. What would remain a nagging material problem is opening the gateway of induction into the virtual realm wide. The concept of 'space' applied to computer- and other machine- generated virtual realms is a metaphor that invokes something quite different than the fundamental experience of being in the space of the physical world in a body rooted to the ground by gravity, in view of a horizon. Cyberspace is heterogeneous and dispersed, it can be experienced in various degrees of person and immersion and in different symbolic modes as a virtually embodied metaphor where the flesh (or meat body) can't go, but into which disengaged spectral bodies and multiple personas be inducted, fly and interact, alone in an electronic crowd. The scene itself can move and is responsive to the user in ways which promote performative and/or magical experiences, loosely covered in scientific and socio-economic alibis. That is, electronically produced liminal realms and induced experiences are only superficially about technology, they are about transcendence (even when in degraded forms of sex, shopping, high-speed driving, mortal combat, etc.) Some of the organizing metaphors of cyberspace (frontier, highway, spaceflight, cave, net, theater, game, etc.) are propositions which should be scrutinized carefully as to the way they define the control, access, reality status and experiences assigned to the virtual and symbolic realm which is increasingly our everyday world.
Post-biological technologies enable us to become directly involved, body and mind, in our own transformation, and they are bringing about a qualitative change in our being. The emergent faculty of cyberception, our artificially enhanced interactions of perception and cognition, involves the transpersonal technology of global networks and cybermedia. We are learning to see afresh the processes of emergence in nature, the planetary media-flow, the invisible forces and fields of our many realities, while at the same time re-thinking possibilities for the architecture of new worlds. Cyberception not only implies a new body and a new consciousness but a redefinition of how we might live together in the interspace between the virtual and the real, calling for a wholly new social environment and a reconsideration of every aspect of our ways of being. Western architecture shows too much concern with surface and structures - an arrogant "edificiality" - and is too little aware of the human need for transformative systems. There is no biology of building. A city should offer its citizens the opportunity to participate in the process of cultural emergence. Its infrastructure, like its buildings, must be both intelligent and publicly intelligible, comprising systems that anticipate and react to our individual desires and needs as much as we interact with them. A "grow bag" culture is required in which seeding replaces designing, and where architecture finds its guiding metaphors in microsystems and horticulture rather than in monumentality and warfare. Currently, architecture has no response to the realities of cyborg living, or the distributed self, or to the ecology of digital interfaces and network nodes. It has produced a shopping cart world of pre-packed products wheeled around the sterile post-modernity of a mall culture. Buildings, like cities, should grow. As products of creative cyberception, they must become the matrix of new forms of consciousness and of the rhythms and realisations of post-biological life.

Techno music is an aggressive, technology and future oriented genre of youth culture and popular music. The historical background of this musical form lies in the avantgarde groups of 60's and 70's; especially Fluxus and Kraftwerk. From a philosophical point of view, techno can also be seen as a continuation to the modernist avantgarde movements such as futurism, surrealism and dadaism of the early 20th century. Techno music is especially popular in Europe. What used to be pure underground five years ago has become evidently mainstream. The recent commercial success of artists like Sven Vaeth, Westbam, LFO, Orbital, The Orb and Aphex Twin has proved techno to be a fast growing youth movement. Pop journalists and music experts have claimed techno to be "rock of the 90's". Concerning this, its is not surprising that the massive party concepts of Mayday and Love Parade have been called "Woodstocks of the 90's". In my paper I will introduce and analyse the latest developments of techno music and aesthetics. During the recent years techno has divided into several sub-genres such as ambient, trance, hardcore and gabber. A clear turning point can be seen. At its current status quo, techno seems to be a cultural phenomenon with a fascinating mixture of experimental avantgarde music and transnational pop culture. Techno music has been said to be "a soundtrack of the information age". Juergen Laarmann, the editorin-chief of German Frontpage techno magazine, has also written that techno music is only a small part of a broader concept of techno culture. In this case, we have to ask what is techno culture? In Laarmann's opinion all the computer based technologies from computer networks to video games and hypermedia programs represent techno culture. Concerning this point of view, it is interesting to bring up a citation from Bill Nichols' remarkable article "The Work of Culture in the Age of Cybernetic Systems": The Computer is more than an object; it is also an icon and a metaphor that suggests new ways of thinking about ourselves and our environment, new ways of constructing images of what it means to be human and to live in a humanoid world. Cybernetic systems include an entire array of machines and apparatuses that exhibit computational power. Such systems contain a dynamic, even if limited, quotient of intelligence. Telephone networks, communication satellites, radar systems, programmable laser videodiscs, robots, biogenetically engineered cells, rocket guidance systems, videotex networks - all exhibit a capacity to process information and execute actions. They are all "cybernetic" in that they are self-regulating mechanisms or systems within predefined limits and in relation to predefines tasks. Just as the camera has come to symbolise the entirety of the photographic and cinematic processes, the computer has come to symbolise the entire spectrum of networks, systems and devices that exemplify cybernetic of "a utomated but intelligent" behaviour.
Electronic artists rely on technologies developed by disciplines which did not exist just a few decades ago: computer graphics, image processing, computer vision, human-computer interface design, virtual reality and so on. The paper traces the history of these currently prominent image disciplines. My analysis begins in the 1920s when avant-garde artists, inspired by modern engineering, tried to systematically apply its principles to visual communication. To engineer vision meant to be able to affect the viewer with engineering precision, predictability, and effectiveness. Thus, Dziga Vertov championed montage as the most economical kind of communication while Sergei' Eisenstein searched for units to measure communication's efficiency. In its desire to engineer vision, the avant-garde was ahead of its time. The systematic engineering of vision took place only after World War II with the shift to post-industrial society. In post-industrial society, the mental labor of information processing is more important than manual labor. In contrast to a manual worker of the industrial age an operator in a humanmachine system is primarily engaged in the observation of displays which present information in real time about the changing status of a system or an environment, real or virtual: a radar screen tracking a surrounding space; a computer screen updating the prices of stocks; a video screen of a computer game presenting an imaginary battlefield, etc. In short, vision becomes the major instrument of labor, the most productive organ of a worker in a human-machine system. The research into human- machine interfaces — from first computer graphics displays of the late 1940s to today's VR — can be seen as attempts to make the use of vision in this new role as efficient as possible. The importance of information processing for post-industrial society also leads to the necessity to automate as much of it as possible. The ultimate aim is the complete replacement of human cognitive functions by a computer, including the substitution of human vision by computer vision. This is the second trajectory of image research in post-industrial society; from pattern recognition systems of the 1950s to today's computer vision systems. In summary, most of the new research into imaging and vision after World War II can be understood as following two directions: on the one hand, making human vision in its new role of human-machine interface as efficient and as productive as possible; on the other hand, transferring vision from a human to a computer. Why should this historical analysis be of concern to electronic artists? The notion that the artist functions outside of society, history, and industry is a modernist myth. Modernist artists were not only the pioneers of the utilitarian aesthetics of modern industrial design and the techniques of modern advertisement and political propaganda, but they have also pioneered the post-modern engineering of vision, the integration of human and machine in human-machine systems, and the replacement of human vision by computer vision. Today, computer graphics industry is one of the sites of this engineering. Whether computer artists acknowledge or ignore their relationship to this industry, it exists. Acknowledging rather than ignoring this relationship is the first step toward a critical computer art practice.
Art and Technology as the New Avant-garde Machine Vertebral Animal The status and understanding of technology in the computer epoch is very different from 'optic-engine based technology'. As opposed to the human body, an engine is a different body/construction. The human body was understood as a unit, as an undebatable organism. Computer technology can't be separated in reflective categories from the subject and, in a way, from the body. A machine now is not a structure that is alienated from the subject. (Structures don't go on the streets! – slogan of 1968). Technology is intermingled with intimate human life as a part of the 'molecular structure'. Technology seems to be saturated with desire, seduction, 'automata of the body'. It is supposed to be combined with desire with functions of the body and the filters of perception. Assemblage of Representations, Body When making a comparison between the body and the subject we work on the side of the subject. Making analyzable the bodily practices and the unconscious, we are continuing to dissociate the body, from one side and to incorporate it into forms of representations from the other side. The only territory of the body is the terrain of transgression, affect, death, sex. The body is incorporated into language and viewed through a multitude of practices. The practices could be understood as an assemblage of verbal and visual possibilities taken from past and present (marginal and dominant) culture. The Art of the Disembodied Subject a) dislocation. A virtual portrait (in VR games, for example) could include the following: mind, age , character, temperament, style, design, sex. Everything that was articulated, analyzed inside the subject could be terminated and artificially used. A subject is a landscape, open for a multitude of subjects, that can be recombined or segmented for different needs and functions. A subject can't live beyond the cultural media: literature, film, TV. It needs to be disembodied, moved to interfere with other life forms and to be dislocated from the automatic 'natural' body. It has a multitude of images and a freedom of recombining and choosing itself. b) Segmentation and interactivity. Interactivity is different from communication and information. An interactive technology needs a special subject and atactics, that avoids stable codes and emphasizes the process of collaborative acting. The paper will be illustrated with conceptual and video installations by Russian artists and by experts from experimental TV in Russia and the Piazza Virtuale in Kassel.
In his report on the study of pictorial perception among African subjects, William Hudson (1967) says that we take it very much for granted that methods which are only moderately successful in our own cultures will prove equally, if not highly, successful in an alien culture: "We fall into the error of thinking of the black man's mind as a tabula rasa, which we have only to fill with the benefits of our own cultural experience in order to promote whatever objectives we may have in mind. We forget or ignore the fact that the black man possesses his own indigenous culture." During recent years, many artists have addressed the issue of cultural diversity as part of their discussions on Electronic Art. Although the vast majority of artists claim the need for a transcultural approach, most of them have taken a superficial look at this complex problem, turning attention away from some of its more crucial points. Their discourse focuses on the possibilities for providing artistic bridges across different cultures, while their attitudes and works reflect, in many cases, a typical ethnocentric view. The discussion aims at promoting a debate on transcultural issues, as one of the major challenges electronic artists face today. In a world of social, cultural and economic disparities, how can technology meet basic human needs in both developed and developing countries? Which are the dominant cultural values that underlie computer-related technologies today? What is the impact of new electronic technologies on Third World nations? How can we minimize technological dependence and cultural domination, when 30 developed countries – with less than 30% of the world's population – account for approximately 95% of the world's scientific and technological production?
Some artists using electronics take for granted that the art that will be significantly new is going to emerge through new technology. If they look at a painting, they see a medium that doesn't do very much except sit on the wall. Old medium, old ideas. The new media involve intelligent and ambitious systems, radical shifts in our thinking. So it's natural to expect radical and impressive art, too. Working as a painter who also uses computers, I am more sceptical. The art of painting is built on asking questions about what you see, and the process has the feel of a stumbling search. Obsolete? During the sixties and seventies we had exhibitions with "beyond painting" in the title. Kinetic, Op, Minimal, Conceptual, all mixed make-believe and pseudo-science to suggest a future where only "de-materialized" art would be possible. In fact what evaporated wasn't the "art object" but the credibility of this way of thinking, discredited and soon forgotten because the work with real punch and ambition proved to come from painting. As well as finding another country for art – albeit a virtual country – the visual creativity of computing can function just as well within traditional media. The given technology of a painting – flat surface, nothing moving, no sound, no buttons or head-set, not even a plug required – is unimpressive, but it can whirl into life through the touch of colour, the dance of line, the stare of a face. At the Minneapolis conference last year the neighbouring museum held a small exhibition of Matisse's graphic work, its vitality and simplicity a reminder of how far the computer graphic exhibits (mine included) fell short. The technophobia of the mainstream art world is the routine excuse for the failures of computer works to be as impressive as they should be. But on exciting, sophisticated technology is just the starting point. Picasso on an Apple II might still be interesting. Whatever else is possible, a fusion of computer techniques and painterly sensibility shouldn't be discounted too hostily. If there are frontiers in art they certainly aren't where you expect them to be.
Remember Vincent Van Gogh's Painter on His Way to Work, carrying it all on his back? That's where art education is heading. I don't mean the canvas and easel. I mean carrying it all on your back, in the clothes that you wear and in the headband in your hair. 50% pure natural wool 50% optical fibre. I am talking about the interface moving onto and, eventually, into the body. That's your electronic media artist on her way to school. She's wearing the university on her sleeve. We're not talking about a few curriculum changes here. We're not talking about the gradual replacement of some of the library stacks with a few computers. We are talking about the total dissolution, disintegration, and dispersal of Higher Education. From real estate to cyber estate. The university is becoming the interversity. Ask the students. Hundreds of thousands use the Internet daily. When Larry Smart first issued NCSA Mosaic, the network interface to hypermedia browsing, there were ten thousand users in the first three weeks. Now there are over two million. Students are half in school and half in cyberspace. They live between the virtual and the real. They are in the Net more often than out of it. This is the advent of Inter Reality, the space we are most likely to inhabit for the next many years. The ethics of the net, its integrity and inclusiveness, are creating a social behaviour, a morality, which will bring huge bonuses to the real world. I am with Esther Dyson of the Electronic Frontier Foundation when she says that organised political parties won't be needed if open networks "enable people to organise ad hoc, rather than get stuck in some rigid group". The end is to reverse-engineer government, to hack Politics down to its component parts and fix it. She echoes the words of Hazel Henderson writing twenty years before her: "Networks are a combination of invisible college and a modern version of the Committees of Correspondence that our revolutionary forefathers used as vehicles for political change". This post-political process also involves the student in learning to browse, to graze, to hunt for ideas, projects, data, as well as intellectual and artistic collaboration and friendship in all kinds of electronic places, virtual libraries, telecommon rooms and cybercolleges. The students' time in telepresence and virtual learning mode is increasing rapidly. Have you noticed in the studios, libraries and computer suites how every terminal, every interface is occupied, all the time. There are 50 billion adults in the world seeking education in one form or another. That form will be on-line. CD ROM is migrating to big disks at a server near you. The future of education lies in the function of integrated multimedia telecommunication services. But that future could be solely in the hands of big business who simply see "content" as the "value-added" they've got to include to get "market share". I foresee a completely crazy take- over of education by these commercial telecommunications industries unless we can provide models of on-line collaborative creativity and learning whose originality, effectiveness and appeal outshine the more cynical manipulations of the market. We cannot hope to do that in isolation, in our separate colleges, just meeting occasionally, even at conferences as dynamic as this. I want to invoke the sense of a group in which each member has more or less equal power and authority in both access to knowledge and in the means of its reconfiguration and distribution; a group concerned with art and the advancement of learning through collaborative inquiry and shared experience. I want to propose the creation of a Planetary Collegium: non hierarchical , non-linear, and intrinsically interactive; a gathering together, a connecting, an integration of people and ideas. Combining cognition and connectivity, what better creative learning organism could serve our unfolding telematic culture. But by definition such an organism cannot be planned and implemented top down. In fact it is already emerging, bottom-up from the infinity of interactions within the net.
What will be the consequences for art and for education when the digital image is no longer box-dependant? When we no longer have to sit up and beg for information with a typewriter keyboard and TV set? When whole walls of building inside and out can be digitally flooded with sound, colour and light, images and texts flowing in endless transformations, when whole environments respond to our body movements and the articulations of our voices?. When the printed page no longer regiments our thinking into orderly rows of linear data? If the poets, artists and musicians of the world are not ready with strategies to effect this environmental and ecological digitalisation, the politicians, merchants and entrepreneurs will. In this context, Art schools have a clear necessity to put up or shut down. But college is a place for social experiment as much as artistic and intellectual growth. Nothing is more human, warm and convivial than a bunch of kids hanging out on the Internet. As networked virtual reality transports our telepresence, and gives us the tools to reconfigure our own identities, social life will become not only more complex but more imaginative, the scenarios of conviviality outstripping no doubt those of the most fecund scriptwriters of the old movie era. I am happy to admit to possessing a butterfly mind. I'm constantly on the move, physically and virtually, between nodes, between people, between data, between cities, between images, between channels, between texts. I have a psychic restlessness called connectivity. I blame the technology! But then, everyone blames the technology whilst everybody knows that technology has imposed nothing upon us that we did not first desire. Technology arises from our longing to be out-of-body, to see beneath the surface of things and events, to break the bounds of authorised perception, to exceed language, to transform the material world, to recreate ourselves. Technology represents a further embodiment of mind. Minds of course can be vacuous, coldly calculating and analytical, mean and narrow. The same is the case for technology. Minds also can be open, inclusive, loving, spiritual, transcendent. The hope for a cognitive technology lies in this , indeed the hope for a truly human electronic, multimedia and interactive art precisely lies here. The context of this embodiment, the ecology of mind, is at the root of all our considerations about art in the era of interactivity and transformation. With the bionic revelation of our cyborg nature now well rehearsed and understood, it is clear that our art is post-biological also. Again, the educational provision for the development of this post-biological culture must form the overarching agenda of a planetary collegium.
For me, Gelernter can be usefully triangulated with Varela and Stafford because of his project to build a spiritual computer. An emotional computer. Gelernter has valuable things to say about computers and creative thought. "A computer that can't feel can't think". His new book speaks our language. And from his vantage point at Yale, he "rejects the traditional academic subject divisions", and feels "especially at home in the no man's land between art and science". Professor Stafford must feel the same, I would guess, navigating between aesthetics and medicine to chart the emergent revolution in seeing and imaging. Equally, Francisco Varela is not fettered by academic boundaries and roams over an extensive cultural terrain, combining neuroscience with Buddhist theory, and speaking to issues in art as much as society. From these three vantage points, a map of consciousness and the reality we actively construct can be defined. Such vantage points and the new perspectives they cast upon our understanding of ourselves, must become endemic of the learning landscape our Collegium will provide. Not only are students redefining who they are and what they may become, but we too must redefine our identity as teachers, collaborators and guides relative to them. Similarly our tools are changing. While the printed book will continue to be employed, the question becomes how and for what purpose, since it is clear that hypermedia is in many areas set to replace it. The book has come to be the embodiment of authority and its obsolescence as a primary academic tool will cause considerable problems in the academic world. The book is a medium which is fixed and frozen while interactive media are fluid. Post-modernism with its relativist doctrine of layered realities and the slippage of codes has prepared us for the shifting uncertainties of authority, indeed of authorship and ownership of ideas whatever they might constitute, either in science or in art. But the scripting, negotiation and critical evaluation of a hypertext present demands for revolutionary pedagogical change . It's not simply that many colleges are haunted by the ghosts of culture past but that apparitions of the future are emerging on every screen, from every disk, in every network. These apparitions are the constructions of distributed mind, the coming-into-being of new forms of human presence, half real, half virtual, new forms of social relationships, realised in telepresence set in cyberspace. They are challenging the old discarded forms of representation and hermeneutics which still haunt the lecture halls. The students are beginning to treat the university as an interface to Inter Reality as a doorway to a radical constructivism, the way into building their own world. What could be more hopeful than a world designed by the young tested against the on-line wisdom of a global community. This is education in its hyper-Socratic form. There will be no easy transition from the past stability of tradition to the dynamic uncertainty of the immediate future. New priorities must be set in the fiscal affairs of universities. In academic networking and on-line research, change is imminent and difficult times are ahead. "As the Internet expands something will have to give: either the government will stop paying, or politicians will notice that the government is paying and will impose controls, like those imposed by school boards on textbook content or by the FCC on radio and TV broadcasts". The Clipper chip, the cryptography issue, poses serious problems for academic freedom. As Bruce Sterling recently reported from the Conference on Computers, Freedom and Privacy: when the audience was asked by a White House representative who they feared would abuse cryptography more, the US government or criminals, three quarters voted against the government.
