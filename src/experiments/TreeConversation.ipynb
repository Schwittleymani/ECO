{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hello\n",
    "import json, re, time, pickle, locale, os, socket, codecs, sys\n",
    "from random import random, choice, randint, shuffle\n",
    "from collections import OrderedDict\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import Image, display, display_png, display_svg, SVG, clear_output\n",
    "import gensim\n",
    "from jinja2 import Template\n",
    "import pygraphviz as pgv\n",
    "from numpy import int64\n",
    "from ipywidgets import widgets\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'de_DE.utf-8')\n",
    "if not os.path.exists('tree_logs'):\n",
    "    os.makedirs('tree_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"lyrik\": {\n",
    "        \"V3\": {\n",
    "            'sentences' : '/home/marcel/drive/data/eco/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt',\n",
    "            \"model\" : '/mnt/drive1/data/eco/doc2vec_models/parsed_v3_valid.doc2vec'\n",
    "        },\n",
    "        \"V4\": {\n",
    "            \"sentences\" : '/mnt/drive1/data/eco/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid.txt',\n",
    "            \"model\": '/mnt/drive1/data/eco/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid_tagged.doc2vec'\n",
    "        }\n",
    "    },    \n",
    "    \"local\":{\n",
    "        \"V3\": {\n",
    "            \"sentences\": '../../data/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt',\n",
    "            \"model\" : '../../models/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.doc2vec'    \n",
    "        },\n",
    "        \"V4\": {\n",
    "            \"sentences\": '../../data/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid.txt',\n",
    "            \"model\" : '../../data/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid.doc2vec'    \n",
    "        }        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# na which version u wanna go with?\n",
    "V = 4\n",
    "\n",
    "host = socket.gethostname() \n",
    "\n",
    "if host == 'lyrik':\n",
    "    print \"U ARE ON LYRIK\"\n",
    "\n",
    "files_ = files['lyrik'] if host == 'lyrik' else  files['local']\n",
    "files_ = files_['V3'] if V == 3 else files_[\"V4\"]\n",
    "\n",
    "model_file = files_['model']\n",
    "sentences_file = files_['sentences']\n",
    "\n",
    "if not os.path.isfile(model_file):\n",
    "    print \"MODEL FILE IS NOT THERE. GO AND FIND IT\"\n",
    "if not os.path.isfile(sentences_file):\n",
    "    print \"TEXTFILE FILE IS NOT THERE\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = codecs.open(sentences_file, 'r', 'UTF-8')\n",
    "# enum = enumerate(f)\n",
    "# sen = enum.next()\n",
    "# # print sen[1].split(';')[:-1]\n",
    "# print sen[1].split(';')[-1][:-5]\n",
    "# # print ''.join(sen[1].split(';')[:-1]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# progress bar\n",
    "\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 Build sentence list (each sentence needs at least 1 tag)\n",
    "sentences = []\n",
    "\n",
    "f = codecs.open(sentences_file, 'r', 'UTF-8')\n",
    "sentence_count = num_lines = sum(1 for line in open(sentences_file))\n",
    "index = 0\n",
    "for line in log_progress(f, size=sentence_count):\n",
    "    if V == 3:\n",
    "        ls = LabeledSentence(words=line.split(), tags=['SENT_%s' % index])\n",
    "    elif V == 4:\n",
    "        words = line.split(';')[0].split()\n",
    "        #words = ''.join(line[1].split(';')[:-1]).split() \n",
    "        pdf = line.split(';')[1][:-5]\n",
    "        #pdf = line[1].split(';')[:-1][:-5] # getting rid of the .pdf fileending\n",
    "        tag = str(index) + '__' + pdf\n",
    "        ls = LabeledSentence(words= words, tags=[tag])\n",
    "        \n",
    "    sentences.append(ls)\n",
    "    index += 1\n",
    "print len(sentences),'sentences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 TRAINING OR LOADING the doc2vec model and save it\n",
    "# ALTERNATIVE: LOAD THE MODEL IN THE NEXT CELL\n",
    "\n",
    "# tutorial https://rare-technologies.com/doc2vec-tutorial/\n",
    "# proposes shuffling or learning reate adjustment. we gonna do both\n",
    "# in total 20 epochs\n",
    "# took ca. 6.30 hours\n",
    "\n",
    "# FOR SAFETY REASON, BUILD ONLY WHEN FLAG IS SET\n",
    "\n",
    "train_model = False\n",
    "\n",
    "if train_model:\n",
    "    model = gensim.models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "    print('building vocab') \n",
    "    model.build_vocab(sentences)\n",
    "\n",
    "    base_alpha = model.alpha\n",
    "    base_min_alpha = model.min_alpha\n",
    "\n",
    "    for mepoch in range(2):\n",
    "        model.alpha = base_alpha \n",
    "        model.min_alpha = base_min_alpha\n",
    "        for epoch in range(10):\n",
    "            print('epoch',mepoch * 10 + epoch)\n",
    "            model.train(sentences)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "        shuffle(sentences)\n",
    "\n",
    "    # saving the model    \n",
    "    model.save(model_file)\n",
    "    print 'model trained and saved'\n",
    "else:\n",
    "    model = gensim.models.Doc2Vec.load(model_file)\n",
    "    print 'model loaded.',len(model.docvecs), 'vectors'\n",
    "    if len(sentences) != len(model.docvecs):\n",
    "        print 'something is fishy, unequal length: ',len(sentences),'sentences and',len(model.docvecs), 'vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 Tiny helper functions\n",
    "\n",
    "def print_word_list(wl):\n",
    "    str =  ' '.join(wl)\n",
    "    pattern = re.compile('\\s\\W\\s')\n",
    "    shift = 0\n",
    "    for ma in pattern.finditer(str):\n",
    "        str = str[:ma.start(0)-shift]+ma.group(0)[1:]+ str[ma.end(0)-shift:]\n",
    "        shift +=1\n",
    "    if str[-2] == ' ':\n",
    "        str = str[:-2] + str[-1:]\n",
    "    return str\n",
    "\n",
    "def get_print(sentence_or_similar):\n",
    "    if type(sentence_or_similar) is gensim.models.doc2vec.LabeledSentence:\n",
    "        word_list = sentence_or_similar.words\n",
    "    elif type(sentence_or_similar) is int64 or type(sentence_or_similar) is int: # just an index\n",
    "        word_list = sentences[sentence_or_similar].words\n",
    "    else: # TaggedDocument class\n",
    "        word_list = sentences[int(sentence_or_similar[0])][0]\n",
    "    return print_word_list(word_list)\n",
    "    \n",
    "def get_index_tag(sentence):\n",
    "    return sentence.tags[0]\n",
    "\n",
    "def get_index(sentence_or_similar):\n",
    "    if type(sentence_or_similar) is gensim.models.doc2vec.LabeledSentence:\n",
    "        return int64(get_index_tag(sentence_or_similar).split('__')[0])\n",
    "    else:\n",
    "        return int64(sentence_or_similar[0].split('__')[0])\n",
    "    \n",
    "def equal_word_lists(index1, index2):\n",
    "    wl1 = sentences[index1].words\n",
    "    wl2 = sentences[index2].words\n",
    "    if len(wl1) != len(wl2):\n",
    "        return False\n",
    "    else:\n",
    "        for i in range(len(wl1)):\n",
    "            if wl1[i] != wl2[i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def get_lab_sent_by_similar(similar):\n",
    "    #print get_index(similar)\n",
    "    return sentences[get_index(similar)]\n",
    "\n",
    "def get_similarity_by_index(index1, index2):\n",
    "    return model.docvecs.similarity(index1,index2)\n",
    "\n",
    "def linebreak(sentence, afterChar):\n",
    "    wordlist = sentence.split(' ')\n",
    "    line_length = 0 \n",
    "    result = ''\n",
    "    for word in wordlist:\n",
    "        line_length += len(word)\n",
    "        result += word+' '\n",
    "        if line_length > afterChar:\n",
    "            result += '\\n'\n",
    "            line_length = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .similar{\n",
    "        color: black;\n",
    "    }\n",
    "    .random{\n",
    "        color: red;\n",
    "    }\n",
    "    .parent{\n",
    "        color: blue\n",
    "    }\n",
    "    .next{\n",
    "        color: green\n",
    "    }\n",
    "    .noIndex {\n",
    "        list-style-type: none;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConversationTree:\n",
    "    \n",
    "    def __init__(self, root_sentence):\n",
    "        self.G = pgv.AGraph(strict=True, directed=True)\n",
    "        # Basic styling\n",
    "        self.G.node_attr['shape']='box'\n",
    "        #\n",
    "        self.next_node_id = 0\n",
    "        self.actual_node = None\n",
    "        self.inserted_sentence_indices = []\n",
    "        self.root = self.add_node(root_sentence)\n",
    "        self.actual_node = self.root\n",
    "        self.log_index = 0 # comes from outside\n",
    "         \n",
    "    def add_node(self, sentence, edge_label = [], goto = True):\n",
    "        node = ConversationNode(self, sentence, self.actual_node, edge_label)\n",
    "        self.inserted_sentence_indices.append(node.sentence_index)\n",
    "        if goto:\n",
    "            self.change_actual(node)\n",
    "        return node\n",
    "    \n",
    "    def change_actual(self, new):\n",
    "        if self.actual_node: # None when adding the root\n",
    "            self.actual_node.unstyle()\n",
    "        self.actual_node = new\n",
    "        self.actual_node.style_actual()        \n",
    "    \n",
    "    def next_id(self):\n",
    "        id_ = self.next_node_id \n",
    "        self.next_node_id += 1\n",
    "        return id_        \n",
    "    \n",
    "    def display(self, layout= 'dot', fformat = 'png'):\n",
    "        if fformat not in ['png','svg']:\n",
    "            print 'format is not real',fformat\n",
    "            return\n",
    "        name = 'tree_logs/tree_'+str(self.log_index) + '.'+fformat\n",
    "#         self.create_sub_graph()\n",
    "        tree.G.draw(name, prog = layout)\n",
    "#         self.G.draw(name, prog = layout)\n",
    "        if fformat == 'svg':\n",
    "            display(SVG(name))\n",
    "        else:\n",
    "            display(Image(name))   \n",
    "\n",
    "    def up(self, steps = 1):\n",
    "        for step in range(steps):\n",
    "            if self.actual_node.parent_edge:\n",
    "                self.change_actual(self.actual_node.parent)\n",
    "                        \n",
    "    def remove_node(self, node):\n",
    "        node_to_remove = node\n",
    "        self.up()\n",
    "        self.actual_node.remove_child(node_to_remove)\n",
    "        self.inserted_sentence_indices.remove(node_to_remove.sentence_index)\n",
    "                \n",
    "            \n",
    "    def dump_stories(self):\n",
    "        story_nodes = self.root.find_stories()\n",
    "        story_file_name = 'tree_logs/story_'+str(self.log_index) + '.txt'\n",
    "        with codecs.open(story_file_name, 'w', 'UTF-8') as out:\n",
    "            for index, node in enumerate(story_nodes):\n",
    "                story = node.get_story()\n",
    "                out.write('Story '+ str(index) + ', id '+ str(node.id_) +'\\n')\n",
    "                for sen in story:\n",
    "                    out.write(sen+'\\n')\n",
    "            \n",
    "        \n",
    "    ### DOV2VEC stuff\n",
    "\n",
    "    def get_similars(self):\n",
    "        return self.actual_node.get_similars()\n",
    "    \n",
    "    def get_all_options(self):\n",
    "        return self.actual_node.get_all_options()\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    def display_options(self):\n",
    "        all_options = self.actual_node.get_all_options()\n",
    "        template = Template('''\n",
    "        <h2>{{sentence}}</h2>\n",
    "        <ol>\n",
    "        {% for item in options %}\n",
    "        <li class={{item.type}} id=\"ind{{loop.index}}\">{{item.hint}} {{item.sentence}} / {{item.similarity}}</li>\n",
    "        {% endfor %}\n",
    "        {% if delete %}\n",
    "        <li class='noIndex'> d: {{delete}} - remove and up(only cool for leafes so far) </li>\n",
    "        {% endif %}\n",
    "        <li class='noIndex'> s: {{story_end}} - swap story-end </li>\n",
    "        <li class='noIndex'> q: {{end}} - end </li>\n",
    "        </ol>\n",
    "        ''')\n",
    "        sentence = self.actual_node.pretty_print()\n",
    "        params = {\n",
    "            'sentence' : sentence,\n",
    "            'options' : all_options, \n",
    "            'end' : u'ðŸ’£', \n",
    "            'story_end': u'ðŸ“–'\n",
    "        }\n",
    "        if self.actual_node.parent:\n",
    "            params['delete'] = u'âœ‚ï¸'\n",
    "        display(HTML(template.render(params)))\n",
    "        return all_options\n",
    "\n",
    "    def select_option(self):\n",
    "        all_options = self.display_options()\n",
    "        time.sleep(0.2)\n",
    "        selection = raw_input(\"what's next?\") \n",
    "        if selection == 'q':\n",
    "            return False\n",
    "        elif selection == 'd':\n",
    "            self.remove_node(self.actual_node)\n",
    "\n",
    "        elif selection == 's':\n",
    "            self.actual_node.swap_story_end()\n",
    "            return True\n",
    "        else:\n",
    "            try:\n",
    "                selected_index = int(selection)\n",
    "            except ValueError:\n",
    "                return True\n",
    "            if selected_index >= 1 and selected_index <= len(all_options):\n",
    "                selected_option =  all_options[selected_index - 1]\n",
    "    #             print selected_option['index'], self.actual_node.children\n",
    "                if selected_option['type'] == 'parent':\n",
    "                    self.up()\n",
    "                elif selected_option['index'] in self.actual_node.children:\n",
    "                    self.change_actual(self.actual_node.children[selected_option['index']])\n",
    "                else:\n",
    "                    selected_sentence = sentences[int(selected_option['index'])]\n",
    "                    edge_label = [selected_option['similarity'], selected_option['type']]\n",
    "                    self.add_node(selected_sentence, edge_label)\n",
    "        return True\n",
    "\n",
    "    def log(self):\n",
    "        with open('tree_logs/tree_'+str(self.log_index)+'.json','w') as out:\n",
    "            out.write(json.dumps(self.to_json()))\n",
    "                \n",
    "    def to_json(self):\n",
    "        dict_ = self.root.to_json()\n",
    "        dict_['next_node_id'] = self.next_node_id \n",
    "        dict_['actual_node_id'] = self.actual_node.id_\n",
    "        return dict_\n",
    "    \n",
    "    def from_json(self, dict_):\n",
    "        self.root.from_json(dict_)\n",
    "        self.next_node_id = dict_['next_node_id']\n",
    "            \n",
    "class ConversationNode():\n",
    "    \n",
    "    def __init__(self, conv_tree, sentence, parent, edge_label = []):\n",
    "        self.conv_tree = conv_tree\n",
    "        self.graph = conv_tree.G  \n",
    "        self.id_ = conv_tree.next_id()\n",
    "        self.sentence = sentence\n",
    "        self.sentence_index = get_index(self.sentence)\n",
    "        self.label = self.build_label()\n",
    "        self.child_edges = OrderedDict()\n",
    "        self.children = OrderedDict()\n",
    "        self.g_node = self.update_graph()\n",
    "        self.style({'style':'filled', 'fillcolor':'azure3', 'label': self.label})\n",
    "        self.options = None\n",
    "        self.is_leaf = True\n",
    "        self.story_end = True\n",
    "        if parent:\n",
    "            self.parent = parent\n",
    "            self.parent_edge = parent.add_child(self, edge_label)\n",
    "            self.level = parent.level + 1\n",
    "        else:\n",
    "            self.parent = None\n",
    "            self.parent_edge = None\n",
    "            self.level = 0\n",
    "    \n",
    "    def build_label(self):\n",
    "        if V == 4:\n",
    "            pdf_label = sentences[self.sentence_index].tags[0].split('__')[1]\n",
    "            return str(self.id_) +', '+ str(self.sentence_index) + ', ' + linebreak(self.pretty_print(),30) + linebreak('     ', 1) + linebreak(pdf_label, 5)\n",
    "        return str(self.id_) +', '+ str(self.sentence_index) +   ' | ' + linebreak(self.pretty_print(),30)\n",
    "    \n",
    "    def update_graph(self):\n",
    "        self.graph.add_node(self.id_)\n",
    "        g_node = self.graph.get_node(self.id_)\n",
    "        return g_node\n",
    "    \n",
    "    def add_child(self, node, edge_label = []):\n",
    "        self.children[node.sentence_index]  = node\n",
    "        child_edge = ConversationEdge(self, node,edge_label)   \n",
    "        self.child_edges[node.sentence_index] = child_edge\n",
    "        if self.is_leaf:\n",
    "            self.set_leaf(False)\n",
    "            self.set_story_end(False)\n",
    "        return child_edge\n",
    "\n",
    "    def remove_child(self, node):\n",
    "        del self.children[node.sentence_index]\n",
    "        del self.child_edges[node.sentence_index]\n",
    "        if len(self.children) == 0:\n",
    "            self.set_leaf(True)\n",
    "            self.set_story_end(True)\n",
    "        self.graph.delete_node(node.id_)\n",
    "        \n",
    "    def remove_all_children(self):\n",
    "        for child in self.children.values():\n",
    "            child.remove_all_children()\n",
    "            self.remove_child(child)\n",
    "            \n",
    "    def style(self, style_dict):\n",
    "        for k,v in style_dict.iteritems():\n",
    "            self.g_node.attr[k] = v\n",
    "    \n",
    "    def style_actual(self):\n",
    "        self.style({'color': \"orange\"}) \n",
    "        \n",
    "    def unstyle(self):\n",
    "        self.style({'color': \"black\"})\n",
    "        \n",
    "    def pretty_print(self):\n",
    "        return get_print(self.sentence)\n",
    "    \n",
    "    def set_leaf(self, leaf):\n",
    "        self.is_leaf = leaf\n",
    "            \n",
    "    def set_story_end(self, story_end):\n",
    "        self.story_end = story_end\n",
    "        self.style({'fillcolor':'azure3' if self.story_end else 'none'})\n",
    "        \n",
    "    def swap_story_end(self):\n",
    "        self.set_story_end(not self.story_end)\n",
    "        \n",
    "    # doc2vec stuff\n",
    "    \n",
    "    def get_similars(self):\n",
    "        similars =  model.docvecs.most_similar(get_index_tag(self.sentence),topn = num_similars)\n",
    "        return [self.optionFormat(simi) for simi in similars]\n",
    "    \n",
    "    def get_randoms(self):\n",
    "        randoms = []\n",
    "        for index in range(num_random):\n",
    "            rnd_sen = sentences[randint(0,len(sentences))]\n",
    "            randoms.append(rnd_sen)     \n",
    "        return [self.optionFormat(ran) for ran in randoms]\n",
    "    \n",
    "    def get_all_options(self):\n",
    "        if not self.options:\n",
    "            all_options = []\n",
    "            self.similars = self.get_similars()\n",
    "            self.randoms = self.get_randoms()\n",
    "            all_options.extend(self.similars)\n",
    "            if self.parent:\n",
    "                all_options.append(self.optionFormat(self.parent, 'parent'))\n",
    "            if self.sentence_index < len(sentences) - 2:\n",
    "                all_options.append(self.optionFormat(sentences[self.sentence_index + 1],'next'))\n",
    "            all_options.extend(self.randoms)\n",
    "            self.options = all_options\n",
    "        for option in self.options:\n",
    "            if option['type'] == 'parent':\n",
    "                option['hint'] = u'ðŸ‘´ðŸ¼'\n",
    "            elif option['type'] == 'next':\n",
    "                option['hint'] = u'âž¡ï¸'\n",
    "            else:\n",
    "                option['hint'] = u''\n",
    "            if option['type'] != \"parent\" and option['index'] in self.conv_tree.inserted_sentence_indices:\n",
    "                option['hint'] += u'â˜ï¸'\n",
    "            if option['index'] in self.children:\n",
    "                option['hint'] += u'ðŸ‘¶'\n",
    "        return self.options\n",
    "\n",
    "    def optionFormat(self, something, info = ''):\n",
    "        d = {'hint' : ''}\n",
    "        if type(something) is gensim.models.doc2vec.LabeledSentence:\n",
    "            d['index'] = get_index(something) \n",
    "            d['similarity'] = (\"%.3f\" % get_similarity_by_index(self.sentence_index, d['index'])) \n",
    "            d['sentence'] = get_print(something)\n",
    "            d['type'] = 'random'\n",
    "            if info == 'next':\n",
    "                d['type'] = 'next'\n",
    "        # similars e.g. ('SENT_78', 0.790978193283081)\n",
    "        elif isinstance(something, tuple):\n",
    "            d['index'] = get_index(something)\n",
    "            d['similarity'] = (\"%.3f\" % something[1])\n",
    "            d['sentence'] = get_print(sentences[d['index']])\n",
    "            d['type'] = 'similar'\n",
    "        elif isinstance(something, ConversationNode):\n",
    "            d['index'] = something.sentence_index\n",
    "            d['similarity'] =(\"%.3f\" % get_similarity_by_index(self.sentence_index, something.sentence_index))\n",
    "            d['sentence'] = get_print(something.sentence)\n",
    "            d['type'] = 'parent'\n",
    "        return d\n",
    "    \n",
    "    def to_json(self):\n",
    "        dict_ =  OrderedDict(\n",
    "            [('id' , self.id_),\n",
    "            ('sentence', self.sentence),\n",
    "            ('sentence_index', self.sentence_index),\n",
    "            ('story_end', self.story_end),\n",
    "            ('children', zip(\n",
    "                [edge.to_json() for edge in self.child_edges.values()],\n",
    "                [child.to_json() for child in self.children.values()]))]\n",
    "        )\n",
    "        if self.conv_tree.actual_node is self:\n",
    "            dict_['actual_node'] = '<<<<<<<<<<<<<<<<<<<'\n",
    "        return dict_\n",
    "\n",
    "    def from_json(self, dict_):\n",
    "        self.id_ = dict_['id']\n",
    "        self.sentence = LabeledSentence(words = dict_['sentence'][0], tags = dict_['sentence'][1])\n",
    "        self.sentence_index = dict_['sentence_index']\n",
    "        self.label = self.build_label()\n",
    "        self.child_edges = OrderedDict()\n",
    "        self.children = OrderedDict()\n",
    "        if 'actual_node' in dict_:\n",
    "            self.conv_tree.change_actual(self)\n",
    "        self.g_node = self.update_graph()\n",
    "        for edge_child in dict_['children']:\n",
    "            sentence = LabeledSentence(words = edge_child[1]['sentence'][0], tags = edge_child[1]['sentence'][1])  \n",
    "            child = ConversationNode(self.conv_tree, sentence, self,edge_child[0])\n",
    "            child.from_json(edge_child[1])\n",
    "        self.set_story_end(dict_['story_end'])\n",
    "        self.conv_tree.inserted_sentence_indices.append(self.sentence_index)\n",
    "\n",
    "    def find_stories(self):\n",
    "        result = []\n",
    "        if self.story_end:\n",
    "            result.append(self)\n",
    "        for child in self.children.values():\n",
    "            result.extend(child.find_stories())\n",
    "        return result\n",
    "\n",
    "    def get_story(self):\n",
    "        sentences = []\n",
    "        node = self\n",
    "        while node.parent:\n",
    "            sentences.append(get_print(node.sentence))\n",
    "            node = node.parent\n",
    "        sentences.append(get_print(node.sentence))\n",
    "        sentences.reverse()\n",
    "        return sentences\n",
    "    \n",
    "class ConversationEdge(object):\n",
    "        \n",
    "    def __init__(self,from_node, to_node , label = []):\n",
    "        self.id_ = (from_node.id_, to_node.id_)\n",
    "        self.from_node = from_node\n",
    "        self.to_node = to_node\n",
    "        self.g_edge = self.update_graph()\n",
    "        self.style({'label':' '+label[0]})\n",
    "        self.type= 'similar'\n",
    "        self.similarity = label[0]\n",
    "        if label[1] == 'next':\n",
    "            self.style({'color':'green'})\n",
    "            self.type= 'next'\n",
    "        elif label[1] == 'random':\n",
    "            self.style({'color':'red'})\n",
    "            self.type= 'random'\n",
    "      \n",
    "    \n",
    "    def update_graph(self):\n",
    "        self.from_node.graph.add_edge(self.id_)\n",
    "        g_edge = self.from_node.graph.get_edge(*self.id_)     \n",
    "        return g_edge\n",
    "    \n",
    "    def style(self, style_dict):\n",
    "        for k,v in style_dict.iteritems():\n",
    "            self.g_edge.attr[k] = v\n",
    "            \n",
    "    def to_json(self):\n",
    "        return [self.similarity, self.type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_similars = 5\n",
    "num_random = 5\n",
    "\n",
    "load_from_log = False\n",
    "\n",
    "number_logs = max(0,len(filter(lambda file_ : file_.endswith('.json'),\n",
    "                          os.listdir(\"tree_logs\"))) - 1)\n",
    "tree = ConversationTree(choice(sentences))\n",
    "\n",
    "if load_from_log:\n",
    "    log_file = 'tree_logs/tree_'+str(number_logs)+'.json'\n",
    "    with open(log_file,'r') as in_file:   \n",
    "        tree.from_json(json.loads(in_file.read()))\n",
    "    tree.log_index = number_logs\n",
    "else:\n",
    "    tree.log_index = 0 if number_logs == 0 else number_logs + 1\n",
    "\n",
    "while True:\n",
    "    clear_output()\n",
    "    tree.display()\n",
    "    tree.log()\n",
    "    if not tree.select_option():\n",
    "        tree.dump_stories()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tj = tree.to_json()\n",
    "# print json.dumps(tj, indent = 2)\n",
    "tree2 = ConversationTree(sentences[10])\n",
    "tree2.from_json(tj)\n",
    "tree.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "a541bd9ea9f54bb784c073f3a77e2508": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
