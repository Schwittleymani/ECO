{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hello\n",
    "import json, re, time, pickle, locale, os, socket, codecs, sys\n",
    "from random import random, choice, randint, shuffle\n",
    "from collections import OrderedDict\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import Image, display, display_png, display_svg, SVG, clear_output\n",
    "import gensim\n",
    "from jinja2 import Template\n",
    "import pygraphviz as pgv\n",
    "from numpy import int64\n",
    "from ipywidgets import widgets\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'de_DE.utf-8')\n",
    "if not os.path.exists('tree_logs'):\n",
    "    os.makedirs('tree_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"lyrik\": {\n",
    "        \"V3\": {\n",
    "            'sentences' : '/home/marcel/drive/data/eco/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt',\n",
    "            \"model\" : '/mnt/drive1/data/eco/doc2vec_models/parsed_v3_valid.doc2vec'\n",
    "        },\n",
    "        \"V4\": {\n",
    "            \"sentences\" : '/mnt/drive1/data/eco/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid.txt',\n",
    "            \"model\": '/mnt/drive1/data/eco/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid_tagged.doc2vec'\n",
    "        }\n",
    "    },    \n",
    "    \"local\":{\n",
    "        \"V3\": {\n",
    "            \"sentences\": '../../data/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt',\n",
    "            \"model\" : '../../models/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.doc2vec'    \n",
    "        },\n",
    "        \"V4\": {\n",
    "            \"sentences\": '../../data/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid.txt',\n",
    "            \"model\" : '../../data/NAIL_DATAFIELD_txt/parsed_v4/parsed_v4_valid.doc2vec'    \n",
    "        }        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# na which version u wanna go with?\n",
    "V = 3\n",
    "\n",
    "host = socket.gethostname() \n",
    "\n",
    "if host == 'lyrik':\n",
    "    print \"U ARE ON LYRIK\"\n",
    "\n",
    "files_ = files['lyrik'] if host == 'lyrik' else  files['local']\n",
    "files_ = files_['V3'] if V == 3 else files_[\"V4\"]\n",
    "\n",
    "model_file = files_['model']\n",
    "sentences_file = files_['sentences']\n",
    "\n",
    "if not os.path.isfile(model_file):\n",
    "    print \"MODEL FILE IS NOT THERE. GO AND FIND IT\"\n",
    "if not os.path.isfile(sentences_file):\n",
    "    print \"TEXTFILE FILE IS NOT THERE\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# progress bar\n",
    "\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4266193 sentences\n"
     ]
    }
   ],
   "source": [
    "# 2 Build sentence list (each sentence needs at least 1 tag)\n",
    "sentences = []\n",
    "\n",
    "f = codecs.open(sentences_file, 'r', 'UTF-8')\n",
    "sentence_count = num_lines = sum(1 for line in open(sentences_file))\n",
    "index = 0\n",
    "for line in log_progress(f, size=sentence_count):\n",
    "    if V == 3:\n",
    "        ls = LabeledSentence(words=line.split(), tags=['SENT_%s' % index])\n",
    "    elif V == 4:\n",
    "        words = line.split(';')[0].split()\n",
    "        #words = ''.join(line[1].split(';')[:-1]).split() \n",
    "        pdf = line.split(';')[1][:-5]\n",
    "        #pdf = line[1].split(';')[:-1][:-5] # getting rid of the .pdf fileending\n",
    "        tag = str(index) + '__' + pdf\n",
    "        ls = LabeledSentence(words= words, tags=[tag])\n",
    "        \n",
    "    sentences.append(ls)\n",
    "    index += 1\n",
    "print len(sentences),'sentences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded. 4266193 vectors\n"
     ]
    }
   ],
   "source": [
    "# 3 TRAINING OR LOADING the doc2vec model and save it\n",
    "# ALTERNATIVE: LOAD THE MODEL IN THE NEXT CELL\n",
    "\n",
    "# tutorial https://rare-technologies.com/doc2vec-tutorial/\n",
    "# proposes shuffling or learning reate adjustment. we gonna do both\n",
    "# in total 20 epochs\n",
    "# took ca. 6.30 hours\n",
    "\n",
    "# FOR SAFETY REASON, BUILD ONLY WHEN FLAG IS SET\n",
    "\n",
    "train_model = False\n",
    "\n",
    "if train_model:\n",
    "    model = gensim.models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "    print('building vocab') \n",
    "    model.build_vocab(sentences)\n",
    "\n",
    "    base_alpha = model.alpha\n",
    "    base_min_alpha = model.min_alpha\n",
    "\n",
    "    for mepoch in range(2):\n",
    "        model.alpha = base_alpha \n",
    "        model.min_alpha = base_min_alpha\n",
    "        for epoch in range(10):\n",
    "            print('epoch',mepoch * 10 + epoch)\n",
    "            model.train(sentences)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "        shuffle(sentences)\n",
    "\n",
    "    # saving the model    \n",
    "    model.save(model_file)\n",
    "    print 'model trained and saved'\n",
    "else:\n",
    "    model = gensim.models.Doc2Vec.load(model_file)\n",
    "    print 'model loaded.',len(model.docvecs), 'vectors'\n",
    "    if len(sentences) != len(model.docvecs):\n",
    "        print 'something is fishy, unequal length: ',len(sentences),'sentences and',len(model.docvecs), 'vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 Tiny helper functions\n",
    "\n",
    "def print_word_list(wl):\n",
    "    str =  ' '.join(wl)\n",
    "    pattern = re.compile('\\s\\W\\s')\n",
    "    shift = 0\n",
    "    for ma in pattern.finditer(str):\n",
    "        str = str[:ma.start(0)-shift]+ma.group(0)[1:]+ str[ma.end(0)-shift:]\n",
    "        shift +=1\n",
    "    if str[-2] == ' ':\n",
    "        str = str[:-2] + str[-1:]\n",
    "    return str\n",
    "\n",
    "def get_print(sentence_or_similar):\n",
    "    if type(sentence_or_similar) is gensim.models.doc2vec.LabeledSentence:\n",
    "        word_list = sentence_or_similar.words\n",
    "    elif type(sentence_or_similar) is int64 or type(sentence_or_similar) is int: # just an index\n",
    "        word_list = sentences[sentence_or_similar].words\n",
    "    else: # TaggedDocument class\n",
    "        word_list = sentences[int(sentence_or_similar[0])][0]\n",
    "    return print_word_list(word_list)\n",
    "    \n",
    "def get_index_tag(sentence):\n",
    "    return sentence.tags[0]\n",
    "\n",
    "def get_index(sentence_or_similar):\n",
    "    if type(sentence_or_similar) is gensim.models.doc2vec.LabeledSentence:\n",
    "        if V == 3:\n",
    "            return int64(get_index_tag(sentence_or_similar)[5:])\n",
    "        elif V == 4:\n",
    "            return int64(get_index_tag(sentence_or_similar).split('__')[0])\n",
    "    else:\n",
    "        if V == 3:\n",
    "            return int64(sentence_or_similar[0][5:])\n",
    "        elif V == 4:\n",
    "            return int64(sentence_or_similar[0].split('__')[0])\n",
    "    \n",
    "def equal_word_lists(index1, index2):\n",
    "    wl1 = sentences[index1].words\n",
    "    wl2 = sentences[index2].words\n",
    "    if len(wl1) != len(wl2):\n",
    "        return False\n",
    "    else:\n",
    "        for i in range(len(wl1)):\n",
    "            if wl1[i] != wl2[i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def get_lab_sent_by_similar(similar):\n",
    "    #print get_index(similar)\n",
    "    return sentences[get_index(similar)]\n",
    "\n",
    "def get_similarity_by_index(index1, index2):\n",
    "    return model.docvecs.similarity(index1,index2)\n",
    "\n",
    "def linebreak(sentence, afterChar):\n",
    "    wordlist = sentence.split(' ')\n",
    "    line_length = 0 \n",
    "    result = ''\n",
    "    for word in wordlist:\n",
    "        line_length += len(word)\n",
    "        result += word+' '\n",
    "        if line_length > afterChar:\n",
    "            result += '\\n'\n",
    "            line_length = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .similar{\n",
       "        color: black;\n",
       "    }\n",
       "    .random{\n",
       "        color: red;\n",
       "    }\n",
       "    .parent{\n",
       "        color: blue\n",
       "    }\n",
       "    .next{\n",
       "        color: green\n",
       "    }\n",
       "    .noIndex {\n",
       "        list-style-type: none;\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .similar{\n",
    "        color: black;\n",
    "    }\n",
    "    .random{\n",
    "        color: red;\n",
    "    }\n",
    "    .parent{\n",
    "        color: blue\n",
    "    }\n",
    "    .next{\n",
    "        color: green\n",
    "    }\n",
    "    .noIndex {\n",
    "        list-style-type: none;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree convesation\n",
    "\n",
    "Works with 2 main classes and some helper functions\n",
    "\n",
    "### 2 libraries: \n",
    "- _jinja2_ to create HTML templates. makes creating html simpler\n",
    "- _pygraphviz_ for graph visualisation\n",
    "\n",
    "### classes:\n",
    "\n",
    "class **ConversationTree**\n",
    "This class is used as singleton, holds the whole thing together and works as the interface to the user.\n",
    "It gives each inserted node an id, so that the user can directyl jump to specific node. \n",
    "It keps track of the actual selected node and draws the graph (saving it to disc) \n",
    "\n",
    "\n",
    "class **ConversationNode**\n",
    "Each Node in the tree keps track of its relevant information. Sentence, children, actual stying in the graph\n",
    "\n",
    "### Flow:\n",
    "\n",
    "Conversation tree is initiated with a sentence (LabeledSentence), which uses the _add_node_ method to create a root node. Then it loops through _display_tree_ to show the graph and _select_option_ until the end of time (or the user says its enough).\n",
    "\n",
    "__display__\n",
    "\n",
    "Since all nodes take care of their style, whenever the user interacts this method just saves a new image and shows it in the notebook.\n",
    "\n",
    "__select_option__\n",
    "\n",
    "first calls __display_options__, which uses _jinja2_ to create the html output for the actual node and it's options. (sidenote: since jinja template cannot contain emojis we are passing the 'end' and 'story_end' selectors as parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConversationTree:\n",
    "    \n",
    "    def __init__(self, root_sentence):\n",
    "        # pygraphviz Graph\n",
    "        self.G = pgv.AGraph(strict=True, directed=True)\n",
    "        # General styling\n",
    "        self.G.node_attr['shape']='box'\n",
    "        #\n",
    "        self.next_node_id = 0\n",
    "        self.actual_node = None\n",
    "        self.inserted_sentence_indices = []\n",
    "        self.root = self.add_node(root_sentence)\n",
    "        self.actual_node = self.root\n",
    "        self.log_index = 0 # comes from outside\n",
    "         \n",
    "    def add_node(self, sentence, edge_label = [], goto = True):\n",
    "        node = ConversationNode(self, sentence, self.actual_node, edge_label)\n",
    "        self.inserted_sentence_indices.append(node.sentence_index)\n",
    "        if goto:\n",
    "            self.change_actual(node)\n",
    "        return node\n",
    "    \n",
    "    def change_actual(self, new_node):\n",
    "        if self.actual_node: # None when adding the root\n",
    "            self.actual_node.unstyle()\n",
    "        self.actual_node = new_node\n",
    "        self.actual_node.style_actual()        \n",
    "    \n",
    "    def next_id(self):\n",
    "        \"\"\"\n",
    "            return next id and increment internal counter\n",
    "        \"\"\"\n",
    "        id_ = self.next_node_id \n",
    "        self.next_node_id += 1\n",
    "        return id_        \n",
    "    \n",
    "    def display(self, layout= 'dot', fformat = 'png'):\n",
    "        if fformat not in ['png','svg']:\n",
    "            print 'format is not real',fformat\n",
    "            return\n",
    "        name = 'tree_logs/tree_'+str(self.log_index) + '.'+fformat\n",
    "#         self.create_sub_graph()\n",
    "        tree.G.draw(name, prog = layout)\n",
    "#         self.G.draw(name, prog = layout)\n",
    "        if fformat == 'svg':\n",
    "            display(SVG(name))\n",
    "        else:\n",
    "            display(Image(name))   \n",
    "\n",
    "    def up(self, steps = 1):\n",
    "        for step in range(steps):\n",
    "            if self.actual_node.parent_edge:\n",
    "                self.change_actual(self.actual_node.parent)\n",
    "                        \n",
    "    def remove_node(self, node):\n",
    "        node_to_remove = node\n",
    "        self.up()\n",
    "        self.actual_node.remove_child(node_to_remove)\n",
    "        self.inserted_sentence_indices.remove(node_to_remove.sentence_index)\n",
    "                          \n",
    "    def dump_stories(self):\n",
    "        story_nodes = self.root.find_stories()\n",
    "        story_file_name = 'tree_logs/story_'+str(self.log_index) + '.txt'\n",
    "        with codecs.open(story_file_name, 'w', 'UTF-8') as out:\n",
    "            for index, node in enumerate(story_nodes):\n",
    "                story = node.get_story()\n",
    "                out.write('Story '+ str(index) + ', id '+ str(node.id_) +'\\n')\n",
    "                for sen in story:\n",
    "                    out.write(sen+'\\n')\n",
    "            \n",
    "        \n",
    "    ### DOV2VEC stuff\n",
    "\n",
    "    def get_similars(self):\n",
    "        return self.actual_node.get_similars()\n",
    "    \n",
    "    def get_all_options(self):\n",
    "        return self.actual_node.get_all_options()\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    def display_options(self):\n",
    "        all_options = self.actual_node.get_all_options()\n",
    "        template = Template('''\n",
    "        <h2>{{sentence}}</h2>\n",
    "        <ol>\n",
    "        {% for item in options %}\n",
    "        <li class={{item.type}} id=\"ind{{loop.index}}\">{{item.hint}} {{item.sentence}} / {{item.similarity}}</li>\n",
    "        {% endfor %}\n",
    "        {% if delete %}\n",
    "        <li class='noIndex'> d: {{delete}} - remove and up(only cool for leafes so far) </li>\n",
    "        {% endif %}\n",
    "        <li class='noIndex'> s: {{story_end}} - swap story-end </li>\n",
    "        <li class='noIndex'> q: {{end}} - end </li>\n",
    "        </ol>\n",
    "        ''')\n",
    "        sentence = self.actual_node.label# self.actual_node.pretty_print() + \n",
    "        params = {\n",
    "            'sentence' : sentence,\n",
    "            'options' : all_options, \n",
    "            'end' : u'üí£', \n",
    "            'story_end': u'üìñ'\n",
    "        }\n",
    "        if self.actual_node.parent:\n",
    "            params['delete'] = u'‚úÇÔ∏è'\n",
    "        display(HTML(template.render(params)))\n",
    "        return all_options\n",
    "\n",
    "    def select_option(self):\n",
    "        all_options = self.display_options()\n",
    "        time.sleep(0.2)\n",
    "        selection = raw_input(\"what's next?\") \n",
    "        if selection == 'q':\n",
    "            return False\n",
    "        elif selection == 'd':\n",
    "            self.remove_node(self.actual_node)\n",
    "        elif selection == 's':\n",
    "            self.actual_node.swap_story_end()\n",
    "            return True\n",
    "        elif selection.startswith('ID'):\n",
    "            try:\n",
    "                new_id = int(selection[2:])\n",
    "                print('selecting id ' + str(new_id))\n",
    "                new_node = self.find_node(new_id)\n",
    "                if new_node:\n",
    "                    self.change_actual(new_node)\n",
    "                return True\n",
    "            except ValueError:\n",
    "                return True\n",
    "        else:\n",
    "            try:\n",
    "                selected_index = int(selection)\n",
    "            except ValueError:\n",
    "                return True\n",
    "            if selected_index >= 1 and selected_index <= len(all_options):\n",
    "                selected_option = all_options[selected_index - 1]\n",
    "    #             print selected_option['index'], self.actual_node.children\n",
    "                if selected_option['type'] == 'parent':\n",
    "                    self.up()\n",
    "                elif selected_option['index'] in self.actual_node.children:\n",
    "                    self.change_actual(self.actual_node.children[selected_option['index']])\n",
    "                else:\n",
    "                    selected_sentence = sentences[int(selected_option['index'])]\n",
    "                    edge_label = [selected_option['similarity'], selected_option['type']]\n",
    "                    self.add_node(selected_sentence, edge_label)\n",
    "        return True\n",
    "\n",
    "    def log(self):\n",
    "        with open('tree_logs/tree_'+str(self.log_index)+'.json','w') as out:\n",
    "            out.write(json.dumps(self.to_json()))\n",
    "                \n",
    "    def to_json(self):\n",
    "        dict_ = self.root.to_json()\n",
    "        dict_['next_node_id'] = self.next_node_id \n",
    "        dict_['actual_node_id'] = self.actual_node.id_\n",
    "        return dict_\n",
    "    \n",
    "    def from_json(self, dict_):\n",
    "        self.root.from_json(dict_)\n",
    "        self.next_node_id = dict_['next_node_id']\n",
    "        \n",
    "    def find_node(self, id):\n",
    "        return self.root.find_node(id)\n",
    "            \n",
    "class ConversationNode():\n",
    "    \n",
    "    def __init__(self, conv_tree, sentence, parent, edge_label = []):\n",
    "        self.conv_tree = conv_tree\n",
    "        self.graph = conv_tree.G  \n",
    "        self.id_ = conv_tree.next_id()\n",
    "        self.sentence = sentence\n",
    "        self.sentence_index = get_index(self.sentence)\n",
    "        self.label = self.build_label()\n",
    "        self.child_edges = OrderedDict()\n",
    "        self.children = OrderedDict()\n",
    "        self.g_node = self.update_graph()\n",
    "        self.style({'style':'filled', 'fillcolor':'azure3', 'label': self.label})\n",
    "        self.options = None\n",
    "        self.is_leaf = True\n",
    "        self.story_end = True\n",
    "        if parent:\n",
    "            self.parent = parent\n",
    "            self.parent_edge = parent.add_child(self, edge_label)\n",
    "            self.level = parent.level + 1\n",
    "        else:\n",
    "            self.parent = None\n",
    "            self.parent_edge = None\n",
    "            self.level = 0\n",
    "    \n",
    "    def build_label(self):\n",
    "        if V == 3:\n",
    "            return str(self.id_) +', '+ str(self.sentence_index) +   ' | ' + linebreak(self.pretty_print(),30)\n",
    "        if V == 4:\n",
    "            pdf_label = sentences[self.sentence_index].tags[0].split('__')[1]\n",
    "            return str(self.id_) +', '+ str(self.sentence_index) + ', ' + linebreak(self.pretty_print(),30) + ', ' + linebreak(pdf_label, 30)\n",
    "        \n",
    "    \n",
    "    def update_graph(self):\n",
    "        self.graph.add_node(self.id_)\n",
    "        g_node = self.graph.get_node(self.id_)\n",
    "        return g_node\n",
    "    \n",
    "    def add_child(self, node, edge_label = []):\n",
    "        self.children[node.sentence_index]  = node\n",
    "        child_edge = ConversationEdge(self, node,edge_label)   \n",
    "        self.child_edges[node.sentence_index] = child_edge\n",
    "        if self.is_leaf:\n",
    "            self.set_leaf(False)\n",
    "            self.set_story_end(False)\n",
    "        return child_edge\n",
    "\n",
    "    def remove_child(self, node):\n",
    "        del self.children[node.sentence_index]\n",
    "        del self.child_edges[node.sentence_index]\n",
    "        if len(self.children) == 0:\n",
    "            self.set_leaf(True)\n",
    "            self.set_story_end(True)\n",
    "        self.graph.delete_node(node.id_)\n",
    "        \n",
    "    def remove_all_children(self):\n",
    "        for child in self.children.values():\n",
    "            child.remove_all_children()\n",
    "            self.remove_child(child)\n",
    "            \n",
    "    def style(self, style_dict):\n",
    "        for k,v in style_dict.iteritems():\n",
    "            self.g_node.attr[k] = v\n",
    "    \n",
    "    def style_actual(self):\n",
    "        self.style({'color': \"orange\"}) \n",
    "        \n",
    "    def unstyle(self):\n",
    "        self.style({'color': \"black\"})\n",
    "        \n",
    "    def pretty_print(self):\n",
    "        return get_print(self.sentence)\n",
    "    \n",
    "    def set_leaf(self, leaf):\n",
    "        self.is_leaf = leaf\n",
    "            \n",
    "    def set_story_end(self, story_end):\n",
    "        self.story_end = story_end\n",
    "        self.style({'fillcolor':'azure3' if self.story_end else 'none'})\n",
    "        \n",
    "    def swap_story_end(self):\n",
    "        self.set_story_end(not self.story_end)\n",
    "        \n",
    "    # doc2vec stuff\n",
    "    \n",
    "    def get_similars(self):\n",
    "        similars =  model.docvecs.most_similar(get_index_tag(self.sentence),topn = num_similars)\n",
    "        return [self.optionFormat(simi) for simi in similars]\n",
    "    \n",
    "    def get_randoms(self):\n",
    "        randoms = []\n",
    "        for index in range(num_random):\n",
    "            rnd_sen = sentences[randint(0,len(sentences))]\n",
    "            randoms.append(rnd_sen)     \n",
    "        return [self.optionFormat(ran) for ran in randoms]\n",
    "    \n",
    "    def get_all_options(self):\n",
    "        if not self.options:\n",
    "            all_options = []\n",
    "            self.similars = self.get_similars()\n",
    "            self.randoms = self.get_randoms()\n",
    "            all_options.extend(self.similars)\n",
    "            if self.parent:\n",
    "                all_options.append(self.optionFormat(self.parent, 'parent'))\n",
    "            if self.sentence_index < len(sentences) - 2:\n",
    "                all_options.append(self.optionFormat(sentences[self.sentence_index + 1],'next'))\n",
    "            all_options.extend(self.randoms)\n",
    "            self.options = all_options\n",
    "        for option in self.options:\n",
    "            if option['type'] == 'parent':\n",
    "                option['hint'] = u'üë¥üèº'\n",
    "            elif option['type'] == 'next':\n",
    "                option['hint'] = u'‚û°Ô∏è'\n",
    "            else:\n",
    "                option['hint'] = u''\n",
    "            if option['type'] != \"parent\" and option['index'] in self.conv_tree.inserted_sentence_indices:\n",
    "                option['hint'] += u'‚òùÔ∏è'\n",
    "            if option['index'] in self.children:\n",
    "                option['hint'] += u'üë∂'\n",
    "        return self.options\n",
    "\n",
    "    def optionFormat(self, something, info = ''):\n",
    "        d = {'hint' : ''}\n",
    "        if type(something) is gensim.models.doc2vec.LabeledSentence:\n",
    "            d['index'] = get_index(something) \n",
    "            d['similarity'] = (\"%.3f\" % get_similarity_by_index(self.sentence_index, d['index'])) \n",
    "            d['sentence'] = get_print(something)\n",
    "            d['type'] = 'random'\n",
    "            if info == 'next':\n",
    "                d['type'] = 'next'\n",
    "        # similars e.g. ('SENT_78', 0.790978193283081)\n",
    "        elif isinstance(something, tuple):\n",
    "            d['index'] = get_index(something)\n",
    "            d['similarity'] = (\"%.3f\" % something[1])\n",
    "            d['sentence'] = get_print(sentences[d['index']])\n",
    "            d['type'] = 'similar'\n",
    "        elif isinstance(something, ConversationNode):\n",
    "            d['index'] = something.sentence_index\n",
    "            d['similarity'] =(\"%.3f\" % get_similarity_by_index(self.sentence_index, something.sentence_index))\n",
    "            d['sentence'] = get_print(something.sentence)\n",
    "            d['type'] = 'parent'\n",
    "        return d\n",
    "    \n",
    "    def to_json(self):\n",
    "        dict_ =  OrderedDict(\n",
    "            [('id' , self.id_),\n",
    "            ('sentence', self.sentence),\n",
    "            ('sentence_index', self.sentence_index),\n",
    "            ('story_end', self.story_end),\n",
    "            ('children', zip(\n",
    "                [edge.to_json() for edge in self.child_edges.values()],\n",
    "                [child.to_json() for child in self.children.values()]))]\n",
    "        )\n",
    "        if self.conv_tree.actual_node is self:\n",
    "            dict_['actual_node'] = '<<<<<<<<<<<<<<<<<<<'\n",
    "        return dict_\n",
    "\n",
    "    def from_json(self, dict_):\n",
    "        self.id_ = dict_['id']\n",
    "        self.sentence = LabeledSentence(words = dict_['sentence'][0], tags = dict_['sentence'][1])\n",
    "        self.sentence_index = dict_['sentence_index']\n",
    "        self.label = self.build_label()\n",
    "        self.child_edges = OrderedDict()\n",
    "        self.children = OrderedDict()\n",
    "        if 'actual_node' in dict_:\n",
    "            self.conv_tree.change_actual(self)\n",
    "        self.g_node = self.update_graph()\n",
    "        for edge_child in dict_['children']:\n",
    "            sentence = LabeledSentence(words = edge_child[1]['sentence'][0], tags = edge_child[1]['sentence'][1])  \n",
    "            child = ConversationNode(self.conv_tree, sentence, self,edge_child[0])\n",
    "            child.from_json(edge_child[1])\n",
    "        self.set_story_end(dict_['story_end'])\n",
    "        self.conv_tree.inserted_sentence_indices.append(self.sentence_index)\n",
    "\n",
    "    def find_stories(self):\n",
    "        result = []\n",
    "        if self.story_end:\n",
    "            result.append(self)\n",
    "        for child in self.children.values():\n",
    "            result.extend(child.find_stories())\n",
    "        return result\n",
    "\n",
    "    def get_story(self):\n",
    "        sentences = []\n",
    "        node = self\n",
    "        while node.parent:\n",
    "            sentences.append(get_print(node.sentence))\n",
    "            node = node.parent\n",
    "        sentences.append(get_print(node.sentence))\n",
    "        sentences.reverse()\n",
    "        return sentences\n",
    "    \n",
    "    def find_node(self, id):\n",
    "        if self.id_ == id:\n",
    "            return self\n",
    "        for child in self.children.values():\n",
    "            children_result = child.find_node(id)\n",
    "            if children_result:\n",
    "                return children_result\n",
    "        return None\n",
    "    \n",
    "class ConversationEdge(object):\n",
    "        \n",
    "    def __init__(self,from_node, to_node , label = []):\n",
    "        self.id_ = (from_node.id_, to_node.id_)\n",
    "        self.from_node = from_node\n",
    "        self.to_node = to_node\n",
    "        self.g_edge = self.update_graph()\n",
    "        self.style({'label':' '+label[0]})\n",
    "        self.type= 'similar'\n",
    "        self.similarity = label[0]\n",
    "        if label[1] == 'next':\n",
    "            self.style({'color':'green'})\n",
    "            self.type= 'next'\n",
    "        elif label[1] == 'random':\n",
    "            self.style({'color':'red'})\n",
    "            self.type= 'random'\n",
    "      \n",
    "    \n",
    "    def update_graph(self):\n",
    "        self.from_node.graph.add_edge(self.id_)\n",
    "        g_edge = self.from_node.graph.get_edge(*self.id_)     \n",
    "        return g_edge\n",
    "    \n",
    "    def style(self, style_dict):\n",
    "        for k,v in style_dict.iteritems():\n",
    "            self.g_edge.attr[k] = v\n",
    "            \n",
    "    def to_json(self):\n",
    "        return [self.similarity, self.type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"<script> var points=2</script>\")\n",
    "# print 2\n",
    "\n",
    "sen_x = 0\n",
    "n_sim = 100\n",
    "similars = model.docvecs.most_similar(sen_x,topn = n_sim)\n",
    "s_vecs = [] # doc vecs\n",
    "s_sen = [] # sentences\n",
    "s_vecs.append(model.docvecs[sen_x])\n",
    "s_sen.append(get_print(sen_x))\n",
    "# get the doc vecs of all similars and the sentences into the list\n",
    "for vecs in similars:\n",
    "    s_vecs.append(model.docvecs[int(vecs[0][5:])])\n",
    "    s_sen.append(get_print(int(vecs[0][5:])))\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne that stuff (and transform it into a float array [didnt get it in a np one-liner])  \n",
    "tsne_model = TSNE(n_components=2, random_state=0)\n",
    "tsne_res = tsne_model.fit_transform(s_vecs)\n",
    "tsnes_res_f = [[ts[0].item(),ts[1].item()] for ts in tsne_res ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAA7CAYAAAC9v6s7AAAAAXNSR0IArs4c6QAAFjlJREFUeAHt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\nYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h2>0, 2791697 | In: Climate in Earth‚Äô s History. </h2>\n",
       "        <ol>\n",
       "        \n",
       "        <li class=similar id=\"ind1\"> In: Arctic climate impact assessment, ACIA. / 0.836</li>\n",
       "        \n",
       "        <li class=similar id=\"ind2\"> In Climate and History: Studies in Interdisciplinary History, edited by Robert I. Rotberg and Theodore K. Rabb, 19‚Äì50. / 0.827</li>\n",
       "        \n",
       "        <li class=similar id=\"ind3\"> In: Arctic climate impact assessment, ACIA. / 0.825</li>\n",
       "        \n",
       "        <li class=similar id=\"ind4\"> In: Tides and Resonances in the Solar System. / 0.810</li>\n",
       "        \n",
       "        <li class=similar id=\"ind5\"> In: The History of Earth‚Äô s Crust. / 0.805</li>\n",
       "        \n",
       "        <li class=similar id=\"ind6\"> In: Weather, Climate and Human Affairs. / 0.799</li>\n",
       "        \n",
       "        <li class=similar id=\"ind7\"> In: Annals of the International Geophysical Year, Vol. / 0.794</li>\n",
       "        \n",
       "        <li class=similar id=\"ind8\"> In Walter Benjamin: Selected Writings, vol. / 0.789</li>\n",
       "        \n",
       "        <li class=similar id=\"ind9\"> In: Lectures on Mathematical Analysis of Biological Phenomena, pp. / 0.786</li>\n",
       "        \n",
       "        <li class=similar id=\"ind10\"> In The Quest: History and Meaning in Religion. / 0.783</li>\n",
       "        \n",
       "        <li class=similar id=\"ind11\"> In: RauÃÅl Rojas and Ulf Hashagen, eds. / 0.783</li>\n",
       "        \n",
       "        <li class=similar id=\"ind12\"> In Climate and History: Studies in Interdisciplinary History, edited by Robert I. Rotberg and Theodore K. Rabb, 215‚Äì32. / 0.783</li>\n",
       "        \n",
       "        <li class=similar id=\"ind13\"> In: European Science Foundation Policy Briefing, December 2000. / 0.782</li>\n",
       "        \n",
       "        <li class=similar id=\"ind14\"> In: Conference Proceedings of Environmental Catastrophes and Recoveries. / 0.780</li>\n",
       "        \n",
       "        <li class=similar id=\"ind15\"> In: RauÃÅl Rojas and Ulf Hashagen, eds. / 0.780</li>\n",
       "        \n",
       "        <li class=next id=\"ind16\">‚û°Ô∏è On the relative importance of the driving forces of plate motion. / 0.388</li>\n",
       "        \n",
       "        <li class=random id=\"ind17\"> Since the harmful ones can be countered, the whole problem of deficiencies in the soil remains to be reassessed. / 0.173</li>\n",
       "        \n",
       "        <li class=random id=\"ind18\"> Here is some advice from lawyers on employee handbooks. / 0.230</li>\n",
       "        \n",
       "        <li class=random id=\"ind19\"> In this way the project has an extensive impact beyond getting mentioned directly in the press. / 0.173</li>\n",
       "        \n",
       "        <li class=random id=\"ind20\"> Cyberpunk outlaws and hackers on the computer frontier. / 0.329</li>\n",
       "        \n",
       "        <li class=random id=\"ind21\"> The predicted increase in evaporation means that demand for water is expected to increase, while less water may be available in the river basins already under stress. / 0.196</li>\n",
       "        \n",
       "        <li class=random id=\"ind22\"> Aller the pattern is set and the gouge cuts arc flush with the surface. / 0.127</li>\n",
       "        \n",
       "        <li class=random id=\"ind23\"> Arahmaiani, a young woman artist whose work was shown at the Second Asia‚ÄìPacific Triennial exhibition in 1996, produced for that exhibition an installation and performance called Nation for Sale. / 0.208</li>\n",
       "        \n",
       "        <li class=random id=\"ind24\"> Now, although Kant may well have personally been reluctant to admit as much, a merely cursory reading of the Critique of Pure Reason will establish that his critical project must implicitly be in agreement with Nietzsche on precisely this issue dealt with in the latter 's note. / 0.186</li>\n",
       "        \n",
       "        <li class=random id=\"ind25\"> First, if the public persists in believing that cloning is a way of recreating dictators or armies of soldiers, it may associate human clones with violence and evil. / 0.137</li>\n",
       "        \n",
       "        <li class=random id=\"ind26\"> Hunters of the dry puna and the salt puna in northern Chile. / 0.074</li>\n",
       "        \n",
       "        <li class=random id=\"ind27\"> The central poetic device in Transtr√∂mer‚Äô s poetry is the metaphor, and his poetic language is distinguished by a high degree of concentration and it is generally exact and concrete. / 0.165</li>\n",
       "        \n",
       "        <li class=random id=\"ind28\"> In July, well after Stewart began his dealings with Oboron, a new Bagle release followed suit. / 0.316</li>\n",
       "        \n",
       "        <li class=random id=\"ind29\"> Unlike plants and organisms, ecosystems do not have an organized center and do not have genomes. / 0.192</li>\n",
       "        \n",
       "        <li class=random id=\"ind30\"> Art criticism becomes productive when it goes beyond the declaration of judgements and instead develops its own questions and criteria. / 0.239</li>\n",
       "        \n",
       "        <li class=random id=\"ind31\"> Instead of trying to eliminate suffering by creating systems of order based upon human reason, Camus suggests that we will finally end our suffering by realizing that it has no meaning. / 0.097</li>\n",
       "        \n",
       "        \n",
       "        <li class='noIndex'> s: üìñ - swap story-end </li>\n",
       "        <li class='noIndex'> q: üí£ - end </li>\n",
       "        </ol>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what's next?q\n"
     ]
    }
   ],
   "source": [
    "num_similars = 15\n",
    "num_random = 15\n",
    "\n",
    "load_from_log = False\n",
    "\n",
    "number_logs = max(0,len(filter(lambda file_ : file_.endswith('.json'),\n",
    "                          os.listdir(\"tree_logs\"))) - 1)\n",
    "tree = ConversationTree(choice(sentences))\n",
    "\n",
    "if load_from_log:\n",
    "    log_file = 'tree_logs/tree_'+str(number_logs)+'.json'\n",
    "    with open(log_file,'r') as in_file:   \n",
    "        tree.from_json(json.loads(in_file.read()))\n",
    "    tree.log_index = number_logs\n",
    "else:\n",
    "    tree.log_index = 0 if number_logs == 0 else number_logs + 1\n",
    "\n",
    "while True:\n",
    "    clear_output()\n",
    "    tree.display()\n",
    "    tree.log()\n",
    "    if not tree.select_option():\n",
    "        tree.dump_stories()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tj = tree.to_json()\n",
    "# print json.dumps(tj, indent = 2)\n",
    "tree2 = ConversationTree(sentences[10])\n",
    "tree2.from_json(tj)\n",
    "tree.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# PYTHON > JS: THIS IS THE WAY TO GO\n",
    "from IPython.display import Javascript\n",
    "Javascript('window.vizObj={};'.format({\"a\":1}))\n",
    "print 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {
    "ef7ceea437f449758eac1c035672555d": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
