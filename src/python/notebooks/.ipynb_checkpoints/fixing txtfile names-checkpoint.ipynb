{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the filenames\n",
    "Goal: don't actually move or rename the file but create a json file with structural information \n",
    "\n",
    "1. Preparing to fix some file names, by checking how many specific punctuation characters they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check where the files are first\n",
    "#! cd ../../../data/NAIL_DATAFIELD_txt/parsed_v3 && pwd && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a json object valid_files with the category folders as keys (e.g. law_legal_theory_prison_ip) and another dict as values:\n",
    "```\n",
    "{\n",
    "    path: <folder_path>,  \n",
    "    valid_files: [\n",
    "        {\n",
    "            file_name: <file_name>,\n",
    "            automatic_name: True|False,\n",
    "            auto_group_assigned: <some_auto_name_group_name> \n",
    "            assigned_to: \"M\"|\"R\",\n",
    "            manually_set: True|False,\n",
    "            author_name: <first_name(,last_name)?>,\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maybe getting better and better auto naming algo is applied. For non auto detected filenames a person is assigned to set the name manually.\n",
    "For each auto naming of a file the descicion tree is run through:\n",
    "\n",
    "### Descicion tree:\n",
    "\n",
    "- auto_name_found:\n",
    "    - yes: auto_named already?\n",
    "        - yes: same name?\n",
    "            - yes: all cool\n",
    "            - no : warning: dont set new name, only when flag set (override_old_auto)\n",
    "        - no : manually_named already?\n",
    "            - yes: same name?\n",
    "                - yes: all cool\n",
    "                - no : critical warning. don't set\n",
    "            - no : cool. set name\n",
    "    - no : auto_named already?\n",
    "        - yes: critical warning. change of algo messed auto nameing up\n",
    "        - no : assign to a person if not assigned already\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_name_groups = ['1comma_1dash','1comma_>1dash','1dash']\n",
    "\n",
    "two_words = re.compile(\"([a-zA-Z]+[,-_]){2}\")\n",
    "\n",
    "class FileDescriptor:\n",
    "    \n",
    "    def __init__(self, file_name, dict_ = None):\n",
    "        self.file_name = file_name\n",
    "        self.auto_named = False # flag indicating that auto name applied\n",
    "        self.auto_group_name = None # auto name rule name for debugging... \n",
    "        self.assigned_to = None # assigned to person (M|R for splitting :D )\n",
    "        self.manually_named = False # flag indicating that name was set manually\n",
    "        self.author_name = \"\" # final author, JUST ONE\n",
    "        \n",
    "        if dict_:\n",
    "            self.from_dict(dict_)\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return self.__dict__.copy()\n",
    "    \n",
    "    def set_from_dict(self, dict_):\n",
    "        self.__dict__ = dict_\n",
    "    \n",
    "    def set_auto_name(self, author_name, auto_group_name, override_old_auto = False, override_manual = False, debug = False):\n",
    "        \"\"\"\n",
    "        contains the desciocion tree. read above\n",
    "        \"\"\"\n",
    "        if debug: print('setting name to',author_name)\n",
    "        # auto_named_already?\n",
    "        if self.auto_named:\n",
    "            if debug: print('auto_named already')\n",
    "            # yes: same name?\n",
    "            if self.author_name == author_name:\n",
    "                # yes: all cool. set the new group anyway\n",
    "                self.auto_group_name = auto_group_name\n",
    "            # no : warning: dont set new name, only when flag set\n",
    "            else:\n",
    "                # check flag set (override_old_auto)\n",
    "                if override_old_auto:\n",
    "                    self.author_name = author_name\n",
    "                    self.auto_group_name = auto_group_name\n",
    "                else:\n",
    "                    print('Warning: New Auto name does not match old one.')\n",
    "                    print(self.file_name,'old',self.author_name,'new auto',author_name)\n",
    "                    print('Not gonna take it. check your algo')\n",
    "        # no (not auto_named_already)\n",
    "        else: \n",
    "            if debug: print('not auto_named yet')\n",
    "            # manually named already?\n",
    "            if self.manually_named:\n",
    "                # yes: same name?\n",
    "                if self.author_name == author_name:\n",
    "                    # yes: all cool\n",
    "                    self.auto_group_name = auto_group_name\n",
    "                # no : only set when flag set (override_manual). Otherwise warning\n",
    "                else:\n",
    "                    if override_manual:\n",
    "                        self.author_name = author_name\n",
    "                        self.auto_group_name = auto_group_name\n",
    "                        self.auto_named = True\n",
    "                        self.manually_named = False\n",
    "                    else:\n",
    "                        print(\"Warning. Name has been set manually already.\")\n",
    "                        print(self.file_name,'old',self.author_name,'new auto',author_name)\n",
    "                        print('Not gonna take it. check your algo')\n",
    "            else:\n",
    "                # new find: name that shit!\n",
    "                self.author_name = author_name\n",
    "                self.auto_group_name = auto_group_name  \n",
    "                self.auto_named = True\n",
    "                        \n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict())\n",
    "    \n",
    "    def auto_name_check(self, debug = False):\n",
    "        \"\"\"\n",
    "        THIS IS THE SMART FUNCTION. IF YOU KNOW SOME GOOD RULES TO FIND THE NAME FROM A TXT FILE PUT IT HERE\n",
    "        \"\"\"\n",
    "        f = self.file_name\n",
    "        auto_name = None\n",
    "        if debug:\n",
    "            print('checking',self.file_name)\n",
    "            print(',',f.count(','),'-',f.count('-'))\n",
    "        if f.count(',') == 1:\n",
    "            if debug: print('1 comma')\n",
    "            # FINAL this is a great set. lastname, firstname - title something like ALBERRO, NORVELL-recording_conceptual_art\n",
    "            if f.count('-') == 1:\n",
    "                auto_name = (f[:f.find('-')].strip(), '1comma_1dash')\n",
    "            # FINAL? here we have the words in the title separated with - or a minus in a a word \n",
    "            elif f.count('-') > 1:\n",
    "                auto_name = (f[:f.find('-')].strip(), '1comma_>1dash')\n",
    "            else:\n",
    "                pass\n",
    "        elif f.count(',') > 1:\n",
    "            pass\n",
    "        # FINAL. basically lastname - something to separate words in the title\n",
    "        elif f.count('-') == 1:\n",
    "            print('1dash')\n",
    "            auto_name = (f[:f.find('-')].strip(), '1dash')\n",
    "        elif f.count('-') > 1:\n",
    "            if debug: print('>1 -')\n",
    "            pass\n",
    "        # not so many anymore. do them manually. often no author\n",
    "        else :\n",
    "            pass\n",
    "        return auto_name    \n",
    "  \n",
    "    def auto_name(self, override_old_auto = False, override_manual = False, debug= False):\n",
    "        auto_name = self.auto_name_check(debug)\n",
    "        if auto_name:\n",
    "            self.set_auto_name(*auto_name, override_old_auto, override_manual, debug)\n",
    "        # TODO add a warning, when we had a auto_name befor and don't get it anymore\n",
    "\n",
    "    def manual_name_options(self):\n",
    "        file_name_alt = self.file_name.replace(' ','')\n",
    "        options = ['set first_name(, last_name)? for',self.file_name,'n: no author']\n",
    "        find_name_match = two_words.match(file_name_alt)\n",
    "        if find_name_match:\n",
    "            potential_name =file_name_alt[:find_name_match.span()[1]-1]\n",
    "            potential_name.replace('-',',')\n",
    "            potential_name.replace('_',',')\n",
    "            splitguess = 'g: ' + potential_name\n",
    "            options.append(splitguess)\n",
    "        options = '\\n'.join(options) + '\\n'\n",
    "        return options\n",
    "\n",
    "    def manual_naming(self):\n",
    "        options = create_options(self.file_name)\n",
    "        name = input(options)\n",
    "        if name == '':\n",
    "            return\n",
    "        else:\n",
    "            if name == 'n':\n",
    "                self.author_name = 'no author'\n",
    "            elif name == 'g':\n",
    "                self.author_name = options[3][2:]\n",
    "            else:\n",
    "                self.author_name = name\n",
    "            self.auto_named = False\n",
    "            # keep auto_name_group so we see, if there was something before\n",
    "            self.manually_named = True\n",
    "\n",
    "    \n",
    "class DescriptorCollection:\n",
    "    \"\"\"\n",
    "    File descriptors for a folder of files\n",
    "    \"\"\"\n",
    "    def __init__(self,folder_name,folder_path):\n",
    "        self.folder_name = folder_name\n",
    "        self.folder_path = folder_path\n",
    "        self.file_descriptors = {}\n",
    "\n",
    "    def to_dict(self):\n",
    "        dict_ = self.__dict__.copy()\n",
    "        dict_['file_descriptors'] = {file_descr: self.file_descriptors[file_descr].to_dict() for file_descr in self.file_descriptors}\n",
    "        return dict_\n",
    "            \n",
    "    def from_dict(self, dict_):\n",
    "        self.__dict__ = dict_\n",
    "        self.log_files = [FileDescriptor('',dict_) for dict_ in self.file_descriptors]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict())\n",
    "    \n",
    "    def short_description(self):\n",
    "        dict_ = self.to_dict().copy()\n",
    "        dict_['file_descriptors'] = len(dict_['file_descriptors'])\n",
    "        return json.dumps(dict_)\n",
    "    \n",
    "    def build(self, file_filter = None, file_name_processor= None):\n",
    "        \"\"\"\n",
    "        for initialisation:\n",
    "        builds a log dict for a list of file in a folder. \n",
    "        the actual selection of files can be filtered with a passed function\n",
    "        for each selected file the empty description is created\n",
    "        \"\"\"\n",
    "#         file_descriptors = {}\n",
    "        for file_ in os.listdir(self.folder_path):\n",
    "            if not file_filter or file_filter(file_):\n",
    "                file_key = file_ \n",
    "                if file_name_processor:\n",
    "                    file_key = file_name_processor(file_)\n",
    "                self.file_descriptors[file_key] = FileDescriptor(file_)\n",
    "#         return log_files\n",
    "    \n",
    "    def get_descriptor(self, file_name_or_index):\n",
    "        if type(file_name_or_index) == str:\n",
    "            return self.file_descriptors[file_name_or_index]\n",
    "        elif type(file_name_or_index) == int:\n",
    "            return list(self.file_descriptors.values())[file_name_or_index]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part is simple.\n",
    "Initiate the description files for our corpus.\n",
    "\n",
    "This is only for initialisation. If it's done you can just **load a log file**...\n",
    "At the end we get a dict, where the keys are foldernames and the values are DescriptorCollections\n",
    "```\n",
    "{\n",
    "    folder_name: {\n",
    "        <DescriptorCollections>: as_json:\n",
    "        folder_name: <folder_name>\n",
    "        folder_path: <folder_path>,\n",
    "        log_files: <list of FileDescriptors>\n",
    "    }\n",
    "},\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_descr_folder(base_path, folder_names, file_filter, file_name_processor):\n",
    "    \"\"\"\n",
    "    build multiple folder in one base folder to a dict\n",
    "    {key: folder_name ; value: {path: folder_path, list of fileDescriptions}}\n",
    "    \"\"\"\n",
    "    descr_collections = []\n",
    "    for folder_name in folder_names:\n",
    "        descr_folder = DescriptorCollection(folder_name, base_path + folder_name)\n",
    "        descr_folder.build(file_filter, file_name_processor)\n",
    "        descr_collections.append(descr_folder)    \n",
    "    return merge_collections(descr_collections)\n",
    "\n",
    "        \n",
    "def merge_collections(descr_collections):\n",
    "    \"\"\"\n",
    "    basically zips together multiple description collections into one dictionary\n",
    "    {key: folder_name ; value: {path: folder_path, list of fileDescriptions}}\n",
    "    \"\"\"\n",
    "    merged_cols = {}\n",
    "    for col in descr_collections:\n",
    "#         print(col.folder_name)\n",
    "        merged_cols[col.folder_name] = col\n",
    "    return merged_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some methods to initiate a set of collections, read and dump them to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_log(base_path, file_filter = None, file_name_processor = None):\n",
    "    \"\"\"\n",
    "    initialises\n",
    "    \"\"\"\n",
    "    folder_names = [obj for obj in os.listdir(base_path) if os.path.isdir(base_path + obj)]\n",
    "    log = build_descr_folder(main_path, folder_names, file_filter, file_name_processor)\n",
    "  \n",
    "    # print(log_files)\n",
    "    for folder in log:\n",
    "        print(folder)\n",
    "        print(len(log_files[folder]['log_files']),'log files')\n",
    "    return log\n",
    "        \n",
    "\n",
    "def read_log():\n",
    "    try:\n",
    "        with codecs.open(log_file,encoding='utf-8') as fin:\n",
    "            log = json.loads(fin.read())\n",
    "    except FileNotFoundError:\n",
    "        update_log_file()\n",
    "    return log\n",
    "\n",
    "# def update_txt(file_name, file_path, data):\n",
    "#     file_log = log.get(file_name,{})\n",
    "#     file_log = {**file_log, **data}\n",
    "#     log[file_name] = file_log\n",
    "\n",
    "def update_log_file(log):\n",
    "    \"\"\"\n",
    "    log is a dict of collection. dump it to drive...\n",
    "    \"\"\"\n",
    "    dict_ = {col: log[col].to_dict() for col in log} \n",
    "    with codecs.open(log_file,'w', encoding='utf-8') as fout:\n",
    "        fout.write(json.dumps(dict_, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arts_arthistory_aesthetics\n",
      "1627 log files\n",
      "digital_and_internet_theory\n",
      "732 log files\n",
      "ecology_climate_permaculture_collapse\n",
      "887 log files\n",
      "library_and_archive_theory\n",
      "57 log files\n",
      "political_theory_anarchist\n",
      "771 log files\n",
      "law_legal_theory_prison_ip\n",
      "599 log files\n",
      "own_mixed_collection\n",
      "132 log files\n",
      "{\n",
      "  \"auto_named\": false,\n",
      "  \"author_name\": \"\",\n",
      "  \"file_name\": \"New-Inquiry-New-Inquiry-Vol-6-Game-Drones_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": null\n",
      "}\n",
      "{\n",
      "  \"auto_named\": false,\n",
      "  \"author_name\": \"\",\n",
      "  \"file_name\": \"Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main_path = '../../../data/NAIL_DATAFIELD_txt/parsed_v3/'\n",
    "\n",
    "def valid_file_filter(file_name):\n",
    "    return '_valid' in file_name\n",
    "\n",
    "def valid_file_name_processor(file_name):\n",
    "    return file_name[:-len('_valid.txt')]\n",
    "\n",
    "log = init_log(main_path, valid_file_filter, valid_file_name_processor)\n",
    "update_log_file(log)\n",
    "\n",
    "# now we can grab a file descriptor either by some index or by it's file name:\n",
    "file_descr = log['arts_arthistory_aesthetics'].get_descriptor(0)\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))\n",
    "file_descr = log['arts_arthistory_aesthetics'].get_descriptor('Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers')\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\n",
      ", 1 - 2\n",
      "1 comma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Batsford', '1comma_>1dash')"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_descr.auto_name_check(debug = True)\n",
    "# that looks good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the auto naming function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\n",
      ", 1 - 2\n",
      "1 comma\n",
      "setting name to Batsford\n",
      "not auto_named yet\n",
      "{\n",
      "  \"auto_named\": true,\n",
      "  \"author_name\": \"Batsford\",\n",
      "  \"file_name\": \"Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": \"1comma_>1dash\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test auto_name\n",
    "file_descr.auto_name(debug= True)\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manual naming could work like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set first_name(, last_name)? for\n",
      "Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\n",
      "n: no author\n",
      "g:Batsford-Gwen\n",
      "\n",
      "{\n",
      "  \"auto_named\": true,\n",
      "  \"author_name\": \"Batsford\",\n",
      "  \"file_name\": \"Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": \"1comma_>1dash\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "file_descr.manual_naming()\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we go through all files in bulk. Instead of `auto_name_check` we use `auto_name`,\n",
    "which will call `set_auto_name` in case we found something.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coming soon to your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arts_arthistory_aesthetics\n",
      "TOTAL 1627\n",
      "AUTHORS 945\n",
      "MANUAL 682\n",
      "sizecheck ok\n",
      "digital_and_internet_theory\n",
      "TOTAL 732\n",
      "AUTHORS 469\n",
      "MANUAL 263\n",
      "sizecheck ok\n",
      "ecology_climate_permaculture_collapse\n",
      "TOTAL 887\n",
      "AUTHORS 476\n",
      "MANUAL 411\n",
      "sizecheck ok\n",
      "library_and_archive_theory\n",
      "TOTAL 57\n",
      "AUTHORS 39\n",
      "MANUAL 18\n",
      "sizecheck ok\n",
      "political_theory_anarchist\n",
      "TOTAL 771\n",
      "AUTHORS 513\n",
      "MANUAL 258\n",
      "sizecheck ok\n",
      "law_legal_theory_prison_ip\n",
      "TOTAL 599\n",
      "AUTHORS 304\n",
      "MANUAL 295\n",
      "sizecheck ok\n",
      "own_mixed_collection\n",
      "TOTAL 132\n",
      "AUTHORS 128\n",
      "MANUAL 4\n",
      "sizecheck ok\n"
     ]
    }
   ],
   "source": [
    "def complete_check():\n",
    "    for folder in valid_files:\n",
    "        file_list = valid_files[folder]['valid_files']\n",
    "        print(folder)\n",
    "        print('TOTAL',len(file_list))\n",
    "\n",
    "        manual = []\n",
    "        author_names = []\n",
    "        \n",
    "        for file_description in file_list:\n",
    "#             print(file_description)\n",
    "            auto_name = file_auto_name_check(file_description)\n",
    "            if auto_name:\n",
    "                author_names.append(auto_name[0])\n",
    "            else:\n",
    "                manual.append(file_description)\n",
    "\n",
    "        print('AUTHORS',len(author_names))\n",
    "        print('MANUAL',len(manual))\n",
    "#         print('sizecheck', 'ok' if len(author_names) + len(manual) == len(file_list) else 'not ok')\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "complete_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test stuff...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leigh_Bowery 5\n",
      "<_sre.SRE_Match object; span=(5, 6), match='_'>\n",
      "_\n"
     ]
    }
   ],
   "source": [
    "two_words = re.compile(\"([a-zA-Z]+[,-_]){2}\")\n",
    "test_w  = 'Leigh_Bowery__Queer_In_fashion__queer_in_art'\n",
    "matches = two_words.match(test_w)\n",
    "s = test_w[:matches.span()[1]-1]\n",
    "print(s,s.find('_'))\n",
    "split_index = re.compile('[-_]').search(s)\n",
    "print(split_index)\n",
    "print(s[split_index.span()[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
