{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the filenames\n",
    "Goal: don't actually move or rename the file but create a json file with structural information \n",
    "\n",
    "1. Preparing to fix some file names, by checking how many specific punctuation characters they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check where the files are first\n",
    "#! cd ../../../data/NAIL_DATAFIELD_txt/parsed_v3 && pwd && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from random import choice\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a json object valid_files with the category folders as keys (e.g. law_legal_theory_prison_ip) and another dict as values:\n",
    "```\n",
    "{\n",
    "    path: <folder_path>,  \n",
    "    valid_files: [\n",
    "        {\n",
    "            file_name: <file_name>,\n",
    "            automatic_name: True|False,\n",
    "            auto_group_assigned: <some_auto_name_group_name> \n",
    "            assigned_to: \"M\"|\"R\",\n",
    "            manually_set: True|False,\n",
    "            author_name: <first_name(,last_name)?>,\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maybe getting better and better auto naming algo is applied. For non auto detected filenames a person is assigned to set the name manually.\n",
    "For each auto naming of a file the descicion tree is run through:\n",
    "\n",
    "### Descicion tree:\n",
    "\n",
    "- auto_name_found:\n",
    "    - yes: auto_named already?\n",
    "        - yes: same name?\n",
    "            - yes: all cool\n",
    "            - no : warning: dont set new name, only when flag set (override_old_auto)\n",
    "        - no : manually_named already?\n",
    "            - yes: same name?\n",
    "                - yes: all cool\n",
    "                - no : critical warning. don't set\n",
    "            - no : cool. set name\n",
    "    - no : auto_named already?\n",
    "        - yes: critical warning. change of algo messed auto nameing up\n",
    "        - no : assign to a person if not assigned already\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_name_groups = ['1comma_1dash','1comma_>1dash','1dash']\n",
    "\n",
    "two_words = re.compile(\"([a-zA-Z]+[,-_]){2}\")\n",
    "\n",
    "class FileDescriptor:\n",
    "    \n",
    "    def __init__(self, file_name, dict_ = None):\n",
    "        self.file_name = file_name\n",
    "        self.auto_named = False # flag indicating that auto name applied\n",
    "        self.auto_group_name = None # auto name rule name for debugging... \n",
    "        self.assigned_to = None # assigned to person (M|R for splitting :D )\n",
    "        self.manually_named = False # flag indicating that name was set manually\n",
    "        self.author_name = \"\" # final author, JUST ONE\n",
    "        \n",
    "        if dict_:\n",
    "            self.from_dict(dict_)\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return self.__dict__.copy()\n",
    "    \n",
    "    def set_from_dict(self, dict_):\n",
    "        self.__dict__ = dict_\n",
    "    \n",
    "    def set_auto_name(self, author_name, auto_group_name, override_old_auto = False, override_manual = False, debug = False):\n",
    "        \"\"\"\n",
    "        contains the desciocion tree. read above\n",
    "        \"\"\"\n",
    "        if debug: print('setting name to',author_name)\n",
    "        # auto_named_already?\n",
    "        if self.auto_named:\n",
    "            if debug: print('auto_named already')\n",
    "            # yes: same name?\n",
    "            if self.author_name == author_name:\n",
    "                # yes: all cool. set the new group anyway\n",
    "                self.auto_group_name = auto_group_name\n",
    "            # no : warning: dont set new name, only when flag set\n",
    "            else:\n",
    "                # check flag set (override_old_auto)\n",
    "                if override_old_auto:\n",
    "                    self.author_name = author_name\n",
    "                    self.auto_group_name = auto_group_name\n",
    "                else:\n",
    "                    print('Warning: New Auto name does not match old one.')\n",
    "                    print(self.file_name,'old',self.author_name,'new auto',author_name)\n",
    "                    print('Not gonna take it. check your algo')\n",
    "        # no (not auto_named_already)\n",
    "        else: \n",
    "            if debug: print('not auto_named yet')\n",
    "            # manually named already?\n",
    "            if self.manually_named:\n",
    "                # yes: same name?\n",
    "                if self.author_name == author_name:\n",
    "                    # yes: all cool\n",
    "                    self.auto_group_name = auto_group_name\n",
    "                # no : only set when flag set (override_manual). Otherwise warning\n",
    "                else:\n",
    "                    if override_manual:\n",
    "                        self.author_name = author_name\n",
    "                        self.auto_group_name = auto_group_name\n",
    "                        self.auto_named = True\n",
    "                        self.manually_named = False\n",
    "                    else:\n",
    "                        print(\"Warning. Name has been set manually already.\")\n",
    "                        print(self.file_name)\n",
    "                        print('old',self.author_name,'new auto',author_name)\n",
    "                        print('Not gonna take it. check your algo')\n",
    "            else:\n",
    "                # new find: name that shit!\n",
    "                self.author_name = author_name\n",
    "                self.auto_group_name = auto_group_name  \n",
    "                self.auto_named = True\n",
    "                        \n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict())\n",
    "    \n",
    "    def auto_name_check(self, debug = False):\n",
    "        \"\"\"\n",
    "        THIS IS THE SMART FUNCTION. IF YOU KNOW SOME GOOD RULES TO FIND THE NAME FROM A TXT FILE PUT IT HERE\n",
    "        \"\"\"\n",
    "        f = self.file_name\n",
    "        auto_name = None\n",
    "        if debug:\n",
    "            print('checking',self.file_name)\n",
    "            print(',',f.count(','),'   -',f.count('-'))\n",
    "        if f.count(',') == 1:\n",
    "            if debug: print('1 comma')\n",
    "            # FINAL this is a great set. lastname, firstname - title something like ALBERRO, NORVELL-recording_conceptual_art\n",
    "            if f.count('-') == 1:\n",
    "                auto_name = (f[:f.find('-')].strip(), '1comma_1dash')\n",
    "            # FINAL? here we have the words in the title separated with - or a minus in a a word \n",
    "            elif f.count('-') > 1:\n",
    "                auto_name = (f[:f.find('-')].strip(), '1comma_>1dash')\n",
    "            else:\n",
    "                pass\n",
    "        elif f.count(',') > 1:\n",
    "            pass\n",
    "        # FINAL. basically lastname - something to separate words in the title\n",
    "        elif f.count('-') == 1:\n",
    "            if debug: print('1dash')\n",
    "            auto_name = (f[:f.find('-')].strip(), '1dash')\n",
    "        elif f.count('-') > 1:\n",
    "            if debug: print('>1 -')\n",
    "            pass\n",
    "        # not so many anymore. do them manually. often no author\n",
    "        else :\n",
    "            pass\n",
    "        return auto_name    \n",
    "  \n",
    "    def auto_name(self, override_old_auto = False, override_manual = False, debug= False):\n",
    "        auto_name = self.auto_name_check(debug)\n",
    "        if auto_name:\n",
    "            self.set_auto_name(*auto_name, override_old_auto, override_manual, debug)\n",
    "        # TODO add a warning, when we had a auto_name befor and don't get it anymore\n",
    "\n",
    "    def manual_name_options(self):\n",
    "        file_name_alt = self.file_name.replace(' ','')\n",
    "        options = ['set first_name(, last_name)? for',self.file_name,'n: no author']\n",
    "        find_name_match = two_words.match(file_name_alt)\n",
    "        if find_name_match:\n",
    "            potential_name =file_name_alt[:find_name_match.span()[1]-1]\n",
    "            potential_name.replace('-',',')\n",
    "            potential_name.replace('_',',')\n",
    "            splitguess = 'g: ' + potential_name\n",
    "            options.append(splitguess)\n",
    "        options = '\\n'.join(options) + '\\n'\n",
    "        return options\n",
    "\n",
    "    def manual_naming(self):\n",
    "        options = create_options(self.file_name)\n",
    "        name = input(options)\n",
    "        if name == '':\n",
    "            return\n",
    "        else:\n",
    "            if name == 'n':\n",
    "                self.author_name = 'no author'\n",
    "            elif name == 'g':\n",
    "                self.author_name = options[3][2:]\n",
    "            else:\n",
    "                self.author_name = name\n",
    "            self.auto_named = False\n",
    "            # keep auto_name_group so we see, if there was something before\n",
    "            self.manually_named = True\n",
    "\n",
    "    \n",
    "class DescriptorCollection:\n",
    "    \"\"\"\n",
    "    File descriptors for a folder of files\n",
    "    \"\"\"\n",
    "    def __init__(self,folder_name,folder_path):\n",
    "        self.folder_name = folder_name\n",
    "        self.folder_path = folder_path\n",
    "        self.file_descriptors = {}\n",
    "\n",
    "    def to_dict(self):\n",
    "        dict_ = self.__dict__.copy()\n",
    "        dict_['file_descriptors'] = {file_descr: self.file_descriptors[file_descr].to_dict() for file_descr in self.file_descriptors}\n",
    "        return dict_\n",
    "            \n",
    "    def from_dict(self, dict_):\n",
    "        self.__dict__ = dict_\n",
    "        self.log_files = [FileDescriptor('',dict_) for dict_ in self.file_descriptors]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict())\n",
    "    \n",
    "    def short_description(self):\n",
    "        dict_ = self.to_dict().copy()\n",
    "        dict_['file_descriptors'] = len(dict_['file_descriptors'])\n",
    "        return json.dumps(dict_)\n",
    "    \n",
    "    def build(self, file_filter = None, file_name_processor= None):\n",
    "        \"\"\"\n",
    "        for initialisation:\n",
    "        builds a log dict for a list of file in a folder. \n",
    "        the actual selection of files can be filtered with a passed function\n",
    "        for each selected file the empty description is created\n",
    "        \"\"\"\n",
    "#         file_descriptors = {}\n",
    "        for file_ in os.listdir(self.folder_path):\n",
    "            if not file_filter or file_filter(file_):\n",
    "                file_key = file_ \n",
    "                if file_name_processor:\n",
    "                    file_key = file_name_processor(file_)\n",
    "                self.file_descriptors[file_key] = FileDescriptor(file_)\n",
    "#         return log_files\n",
    "    \n",
    "    def get_descriptor(self, file_name_or_index):\n",
    "        if type(file_name_or_index) == str:\n",
    "            return self.file_descriptors[file_name_or_index]\n",
    "        elif type(file_name_or_index) == int:\n",
    "            return list(self.file_descriptors.values())[file_name_or_index]\n",
    "        \n",
    "    def auto_name_all(self, override_old_auto = False, override_manual = False, debug= False):\n",
    "        for file_descr in list(self.file_descriptors.values()):\n",
    "            file_descr.auto_name(override_old_auto, override_manual, debug)\n",
    "            \n",
    "    def info(self):\n",
    "        print('Collection:',self.folder_name)\n",
    "        print(len(self.file_descriptors), 'docs')\n",
    "        print(sum([1 for text_descr in list(self.file_descriptors.values()) if text_descr.auto_named]), 'auto named')\n",
    "        sum_man_named = sum([1 for text_descr in list(self.file_descriptors.values()) if text_descr.manually_named])\n",
    "        sum_assigned = sum([1 for text_descr in list(self.file_descriptors.values()) if text_descr.assigned_to])\n",
    "        print(sum_man_named,'/',sum_assigned, 'manually named/assigned')\n",
    "        \n",
    "    def get_all_assigned_to(self, name, only_missing = False):\n",
    "        return [text_descr for text_descr in list(self.file_descriptors.values()) \n",
    "                if text_descr.assigned_to == name and (not only_missing or text_descr.manually_named)]\n",
    " \n",
    "    def merge(other_collection):\n",
    "        \"\"\"\n",
    "        merge in another collection. should be the same basis, just with different file_descriptior values:\n",
    "        manually assigned author names... basically\n",
    "        creates a NEW COLLECTION\n",
    "        Preference goes to auto_naming, if it doens't exist in the 2nd collection. that means the other has a smarter algo\n",
    "        \n",
    "        \"\"\"\n",
    "        for file_descr_name in self.file_descriptors:\n",
    "            # file descriptor not in other collection? weird... ignore\n",
    "            if file_descr_name not in other_collection:\n",
    "                print(file_descr, 'is not in the 2nd collection. not gonna take it')\n",
    "            file_descr1 = self.file_descriptors[file_descr_name]\n",
    "            file_descr2 = other_collection.file_descriptors[file_descr_name]\n",
    "            new_file_descr = FileDescriptor(file_descr1.file_name)\n",
    "            # we need to cover 4 cases. auto-auto, auto-man, man-auto, man-man, \n",
    "            if file_descr1.auto_named and not file_descr2.auto_named\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part is simple.\n",
    "Initiate the description files for our corpus.\n",
    "\n",
    "This is only for initialisation. If it's done you can just **load a log file**...\n",
    "At the end we get a dict, where the keys are foldernames and the values are DescriptorCollections\n",
    "```\n",
    "{\n",
    "    folder_name: {\n",
    "        <DescriptorCollections>: as_json:\n",
    "        folder_name: <folder_name>\n",
    "        folder_path: <folder_path>,\n",
    "        log_files: <list of FileDescriptors>\n",
    "    }\n",
    "},\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_descr_folder(base_path, folder_names, file_filter, file_name_processor):\n",
    "    \"\"\"\n",
    "    build multiple folder in one base folder to a dict\n",
    "    {key: folder_name ; value: {path: folder_path, list of fileDescriptions}}\n",
    "    \"\"\"\n",
    "    descr_collections = []\n",
    "    for folder_name in folder_names:\n",
    "        descr_folder = DescriptorCollection(folder_name, base_path + folder_name)\n",
    "        descr_folder.build(file_filter, file_name_processor)\n",
    "        descr_collections.append(descr_folder)    \n",
    "    return merge_collections(descr_collections)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some methods to initiate a set of collections, read and dump them to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_log(base_path, file_filter = None, file_name_processor = None):\n",
    "    \"\"\"\n",
    "    initialises\n",
    "    \"\"\"\n",
    "    folder_names = [obj for obj in os.listdir(base_path) if os.path.isdir(base_path + obj)]\n",
    "    log = build_descr_folder(main_path, folder_names, file_filter, file_name_processor)\n",
    "  \n",
    "    # print(log_files)\n",
    "    total_size = 0\n",
    "    for folder in log:\n",
    "        print(folder)\n",
    "        print(len(log_files[folder]['log_files']),'log files')\n",
    "        total_size += len(log_files[folder]['log_files'])\n",
    "    print('TOTAL SIZE',total_size)\n",
    "    return log\n",
    "\n",
    "        \n",
    "\n",
    "def read_log():\n",
    "    try:\n",
    "        with codecs.open(log_file,encoding='utf-8') as fin:\n",
    "            log = json.loads(fin.read())\n",
    "    except FileNotFoundError:\n",
    "        update_log_file()\n",
    "    return log\n",
    "\n",
    "# def update_txt(file_name, file_path, data):\n",
    "#     file_log = log.get(file_name,{})\n",
    "#     file_log = {**file_log, **data}\n",
    "#     log[file_name] = file_log\n",
    "\n",
    "def update_log_file(log):\n",
    "    \"\"\"\n",
    "    log is a dict of collection. dump it to drive...\n",
    "    \"\"\"\n",
    "    dict_ = {col: log[col].to_dict() for col in log} \n",
    "    with codecs.open(log_file,'w', encoding='utf-8') as fout:\n",
    "        fout.write(json.dumps(dict_, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arts_arthistory_aesthetics\n",
      "1627 log files\n",
      "digital_and_internet_theory\n",
      "732 log files\n",
      "ecology_climate_permaculture_collapse\n",
      "887 log files\n",
      "library_and_archive_theory\n",
      "57 log files\n",
      "political_theory_anarchist\n",
      "771 log files\n",
      "law_legal_theory_prison_ip\n",
      "599 log files\n",
      "own_mixed_collection\n",
      "132 log files\n",
      "TOTAL SIZE 4805\n",
      "{\n",
      "  \"auto_named\": false,\n",
      "  \"author_name\": \"\",\n",
      "  \"file_name\": \"New-Inquiry-New-Inquiry-Vol-6-Game-Drones_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": null\n",
      "}\n",
      "{\n",
      "  \"auto_named\": false,\n",
      "  \"author_name\": \"\",\n",
      "  \"file_name\": \"Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main_path = '../../../data/NAIL_DATAFIELD_txt/parsed_v3/'\n",
    "\n",
    "def valid_file_filter(file_name):\n",
    "    return '_valid' in file_name\n",
    "\n",
    "def valid_file_name_processor(file_name):\n",
    "    return file_name[:-len('_valid.txt')]\n",
    "\n",
    "log = init_log(main_path, valid_file_filter, valid_file_name_processor)\n",
    "update_log_file(log)\n",
    "\n",
    "# now we can grab a file descriptor either by some index or by it's file name:\n",
    "file_descr = log['arts_arthistory_aesthetics'].get_descriptor(0)\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))\n",
    "file_descr = log['arts_arthistory_aesthetics'].get_descriptor('Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers')\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\n",
      ", 1    - 2\n",
      "1 comma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Batsford', '1comma_>1dash')"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_descr.auto_name_check(debug = True)\n",
    "# that looks good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the auto naming function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\n",
      ", 1    - 2\n",
      "1 comma\n",
      "setting name to Batsford\n",
      "not auto_named yet\n",
      "{\n",
      "  \"auto_named\": true,\n",
      "  \"author_name\": \"Batsford\",\n",
      "  \"file_name\": \"Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": \"1comma_>1dash\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test auto_name\n",
    "file_descr.auto_name(debug= True)\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manual naming could work like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set first_name(, last_name)? for\n",
      "Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\n",
      "n: no author\n",
      "g:Batsford-Gwen\n",
      "\n",
      "{\n",
      "  \"auto_named\": true,\n",
      "  \"author_name\": \"Batsford\",\n",
      "  \"file_name\": \"Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers_valid.txt\",\n",
      "  \"assigned_to\": null,\n",
      "  \"manually_named\": false,\n",
      "  \"auto_group_name\": \"1comma_>1dash\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "file_descr.manual_naming()\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we go through all files in bulk. Instead of `auto_name_check` we use `auto_name`,\n",
    "which will call `set_auto_name` in case we found something.\n",
    "The complete check also allowes us to assign a random 'person name' to each text document which has not been auto_named. At the end, we get an overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: arts_arthistory_aesthetics\n",
      "1627 docs\n",
      "945 auto named\n",
      "0 / 682 manually named/assigned\n",
      "Collection: digital_and_internet_theory\n",
      "732 docs\n",
      "469 auto named\n",
      "0 / 263 manually named/assigned\n",
      "Collection: ecology_climate_permaculture_collapse\n",
      "887 docs\n",
      "476 auto named\n",
      "0 / 411 manually named/assigned\n",
      "Collection: library_and_archive_theory\n",
      "57 docs\n",
      "39 auto named\n",
      "0 / 18 manually named/assigned\n",
      "Collection: political_theory_anarchist\n",
      "771 docs\n",
      "513 auto named\n",
      "0 / 258 manually named/assigned\n",
      "Collection: law_legal_theory_prison_ip\n",
      "599 docs\n",
      "304 auto named\n",
      "0 / 295 manually named/assigned\n",
      "Collection: own_mixed_collection\n",
      "132 docs\n",
      "128 auto named\n",
      "0 / 4 manually named/assigned\n"
     ]
    }
   ],
   "source": [
    "def complete_check(dict_of_collections, assign_equally_to = None, \n",
    "                   override_old_auto = False, override_manual = False, debug= False):\n",
    "    \"\"\"\n",
    "    when assign_equally_to contains a list, it will randomly choose one for each file that is not\n",
    "    auto-named\n",
    "    \"\"\"\n",
    "    for collection in list(dict_of_collections.values()):\n",
    "        collection.auto_name_all()\n",
    "        for file_descr in list(collection.file_descriptors.values()):\n",
    "            if not file_descr.auto_named:\n",
    "                file_descr.assigned_to = choice(assign_equally_to)\n",
    "\n",
    "complete_check(log,['M','R'])\n",
    "for col in log:\n",
    "    log[col].info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at all assigned descriptors of own_mixed_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"nick_bostrom-are_you_living_in_a-computer_simulation_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null},\n",
       " {\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"laboria_cuboniks_xenofeminism_a_politics_for_alienation_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null},\n",
       " {\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"rosa_menkman_the_glitch_momentum_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null},\n",
       " {\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"Xenofeminism2_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null}]"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[file_descr for file_descr in list(log['own_mixed_collection'].file_descriptors.values()) if file_descr.assigned_to]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nice... now lets get all of them assigned to 'R'. I added a function for that, to have it handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"nick_bostrom-are_you_living_in_a-computer_simulation_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null},\n",
       " {\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"laboria_cuboniks_xenofeminism_a_politics_for_alienation_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null},\n",
       " {\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"rosa_menkman_the_glitch_momentum_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null},\n",
       " {\"auto_named\": false, \"author_name\": \"\", \"file_name\": \"Xenofeminism2_valid.txt\", \"assigned_to\": \"M\", \"manually_named\": false, \"auto_group_name\": null}]"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_to_R = log['own_mixed_collection'].get_all_assigned_to('M')\n",
    "assigned_to_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's manually name them and get the info of that collection again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool all done\n",
      "Collection: own_mixed_collection\n",
      "132 docs\n",
      "128 auto named\n",
      "4 / 4 manually named/assigned\n"
     ]
    }
   ],
   "source": [
    "for file_descr in assigned_to_R:\n",
    "    file_descr.manual_naming()\n",
    "    clear_output()\n",
    "print('cool all done')\n",
    "log['own_mixed_collection'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you tired you can write the log now. for later you can also just grab those, which are not set yet. \n",
    "The second parameter 'only_missing' default False does just that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_to_R = log['own_mixed_collection'].get_all_assigned_to('R',True)\n",
    "assigned_to_R\n",
    "# EMPTY SINCE R did all ot his files..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to merge 2 logs. Let's not rely on git with that... :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arts_arthistory_aesthetics arts_arthistory_aesthetics\n",
      "digital_and_internet_theory digital_and_internet_theory\n",
      "ecology_climate_permaculture_collapse ecology_climate_permaculture_collapse\n",
      "library_and_archive_theory library_and_archive_theory\n",
      "political_theory_anarchist political_theory_anarchist\n",
      "law_legal_theory_prison_ip law_legal_theory_prison_ip\n",
      "own_mixed_collection own_mixed_collection\n"
     ]
    }
   ],
   "source": [
    "def merge_logs(log1, log2):\n",
    "    final_log = {}\n",
    "    for col_name in log1:\n",
    "        print(col_name)\n",
    "        if col_name in log2:\n",
    "           final_log[col_name] = log1[col_name].merge(log2[col_name]) \n",
    "merge_logs(log,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test stuff...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leigh_Bowery 5\n",
      "<_sre.SRE_Match object; span=(5, 6), match='_'>\n",
      "_\n"
     ]
    }
   ],
   "source": [
    "two_words = re.compile(\"([a-zA-Z]+[,-_]){2}\")\n",
    "test_w  = 'Leigh_Bowery__Queer_In_fashion__queer_in_art'\n",
    "matches = two_words.match(test_w)\n",
    "s = test_w[:matches.span()[1]-1]\n",
    "print(s,s.find('_'))\n",
    "split_index = re.compile('[-_]').search(s)\n",
    "print(split_index)\n",
    "print(s[split_index.span()[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
