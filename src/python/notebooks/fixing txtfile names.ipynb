{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the filenames\n",
    "Goal: don't actually move or rename the file but create a json file with structural information \n",
    "\n",
    "1. Preparing to fix some file names, by checking how many specific punctuation characters they have\n",
    "2. structure them: each file has a description object `FileDescriptor` . a folder of files are in a `DescriptorCollection` object. the final abstract structure is a dictionary of these collections. This is called a log, which can be stored on the drive\n",
    "3. the auto naming function can be improved\n",
    "4. a runthough of all files can if not auto-named assign persons to them\n",
    "5. a manual naming function, gives options and an input field.\n",
    "6. log files can be (simply) mergerd\n",
    "\n",
    "## DO IT!\n",
    "\n",
    "In order to skip the examples and go straight to the process just execute the 6 required cells, which have class and function definition in them. they are marked like this:\n",
    "\n",
    "```# <<< 1/6```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check where the files are first\n",
    "#! cd ../../../data/NAIL_DATAFIELD_txt/parsed_v3 && pwd && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <<< 1/6\n",
    "import os\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from random import choice\n",
    "from copy import copy\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a json object valid_files with the category folders as keys (e.g. law_legal_theory_prison_ip) and another dict as values:\n",
    "```\n",
    "{\n",
    "    path: <folder_path>,  \n",
    "    valid_files: [\n",
    "        {\n",
    "            file_name: <file_name>,\n",
    "            automatic_name: True|False,\n",
    "            auto_group_assigned: <some_auto_name_group_name> \n",
    "            assigned_to: \"M\"|\"R\",\n",
    "            manually_set: True|False,\n",
    "            author_name: <first_name(,last_name)?>,\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maybe getting better and better auto naming algo is applied. For non auto detected filenames a person is assigned to set the name manually.\n",
    "For each auto naming of a file the descicion tree is run through:\n",
    "\n",
    "### Descicion tree:\n",
    "\n",
    "- auto_name_found:\n",
    "    - yes: auto_named already?\n",
    "        - yes: same name?\n",
    "            - yes: all cool\n",
    "            - no : warning: dont set new name, only when flag set (override_old_auto)\n",
    "        - no : manually_named already?\n",
    "            - yes: same name?\n",
    "                - yes: all cool\n",
    "                - no : critical warning. don't set\n",
    "            - no : cool. set name\n",
    "    - no : auto_named already?\n",
    "        - yes: critical warning. change of algo messed auto nameing up\n",
    "        - no : assign to a person if not assigned already\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< 2/6\n",
    "\n",
    "auto_name_groups = ['1comma_1dash','1comma_>1dash','1dash']\n",
    "\n",
    "two_words = re.compile(\"([a-zA-Z]+[,-_]){2}\")\n",
    "\n",
    "class FileDescriptor:\n",
    "    \n",
    "    def __init__(self, file_name, dict_ = None):\n",
    "        self.file_name = file_name\n",
    "        self.auto_named = False # flag indicating that auto name applied\n",
    "        self.auto_group_name = None # auto name rule name for debugging... \n",
    "        self.assigned_to = None # assigned to person (M|R for splitting :D )\n",
    "        self.manually_named = False # flag indicating that name was set manually\n",
    "        self.author_name = \"\" # final author, JUST ONE\n",
    "        \n",
    "        if dict_:\n",
    "            self.from_dict(dict_)\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return self.__dict__.copy()\n",
    "    \n",
    "    def from_dict(self, dict_):\n",
    "        self.__dict__ = dict_.copy()\n",
    "    \n",
    "    def set_auto_name(self, author_name, auto_group_name, override_old_auto = False, override_manual = False, debug = False):\n",
    "        \"\"\"\n",
    "        contains the desciocion tree. read above\n",
    "        \"\"\"\n",
    "        if debug: print('setting name to',author_name)\n",
    "        # auto_named_already?\n",
    "        if self.auto_named:\n",
    "            if debug: print('auto_named already')\n",
    "            # yes: same name?\n",
    "            if self.author_name == author_name:\n",
    "                # yes: all cool. set the new group anyway\n",
    "                self.auto_group_name = auto_group_name\n",
    "            # no : warning: dont set new name, only when flag set\n",
    "            else:\n",
    "                # check flag set (override_old_auto)\n",
    "                if override_old_auto:\n",
    "                    self.author_name = author_name\n",
    "                    self.auto_group_name = auto_group_name\n",
    "                else:\n",
    "                    print('Warning: New Auto name does not match old one.')\n",
    "                    print(self.file_name,'old',self.author_name,'new auto',author_name)\n",
    "                    print('Not gonna take it. check your algo')\n",
    "        # no (not auto_named_already)\n",
    "        else: \n",
    "            if debug: print('not auto_named yet')\n",
    "            # manually named already?\n",
    "            if self.manually_named:\n",
    "                # yes: same name?\n",
    "                if self.author_name == author_name:\n",
    "                    # yes: all cool\n",
    "                    self.auto_group_name = auto_group_name\n",
    "                # no : only set when flag set (override_manual). Otherwise warning\n",
    "                else:\n",
    "                    if override_manual:\n",
    "                        self.author_name = author_name\n",
    "                        self.auto_group_name = auto_group_name\n",
    "                        self.auto_named = True\n",
    "                        self.manually_named = False\n",
    "                    else:\n",
    "                        print(\"Warning. Name has been set manually already.\")\n",
    "                        print(self.file_name)\n",
    "                        print('old',self.author_name,'new auto',author_name)\n",
    "                        print('Not gonna take it. check your algo')\n",
    "            else:\n",
    "                # new find: name that shit!\n",
    "                self.author_name = author_name\n",
    "                self.auto_group_name = auto_group_name  \n",
    "                self.auto_named = True\n",
    "                        \n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict())\n",
    "    \n",
    "    def auto_name_check(self, debug = False):\n",
    "        \"\"\"\n",
    "        THIS IS THE SMART FUNCTION. IF YOU KNOW SOME GOOD RULES TO FIND THE NAME FROM A TXT FILE PUT IT HERE\n",
    "        \"\"\"\n",
    "        f = self.file_name\n",
    "        auto_name = None\n",
    "        if debug:\n",
    "            print('checking',self.file_name)\n",
    "            print(', :',f.count(','),'   - :',f.count('-'))\n",
    "        if f.count(',') == 1:\n",
    "            if debug: print('found  1 comma')\n",
    "            # FINAL this is a great set. lastname, firstname - title something like ALBERRO, NORVELL-recording_conceptual_art\n",
    "            if f.count('-') == 1:\n",
    "                auto_name = (f[:f.find('-')].strip(), '1comma_1dash')\n",
    "            # FINAL? here we have the words in the title separated with - or a minus in a a word \n",
    "            elif f.count('-') > 1:\n",
    "                auto_name = (f[:f.find('-')].strip(), '1comma_>1dash')\n",
    "            else:\n",
    "                pass\n",
    "        elif f.count(',') > 1:\n",
    "            pass\n",
    "        # FINAL. basically lastname - something to separate words in the title\n",
    "        elif f.count('-') == 1:\n",
    "            if debug: print('found 1dash')\n",
    "            auto_name = (f[:f.find('-')].strip(), '1dash')\n",
    "        elif f.count('-') > 1:\n",
    "            if debug: print('found  >1 -')\n",
    "            pass\n",
    "        # not so many anymore. do them manually. often no author\n",
    "        else :\n",
    "            pass\n",
    "        return auto_name    \n",
    "  \n",
    "    def auto_name(self, override_old_auto = False, override_manual = False, debug= False):\n",
    "        auto_name = self.auto_name_check(debug)\n",
    "        if auto_name:\n",
    "            self.set_auto_name(*auto_name, override_old_auto, override_manual, debug)\n",
    "        # TODO add a warning, when we had a auto_name befor and don't get it anymore\n",
    "\n",
    "    def manual_name_options(self):\n",
    "        file_name_alt = self.file_name.replace(' ','')\n",
    "        options = {'no':'n: no author'}\n",
    "        find_name_match = two_words.match(file_name_alt)\n",
    "        if find_name_match:\n",
    "            potential_name =file_name_alt[:find_name_match.span()[1]-1]\n",
    "            potential_name = potential_name.replace('-',',')\n",
    "            potential_name = potential_name.replace('_',',')\n",
    "            splitguess = 'g: ' + potential_name\n",
    "            options['guess'] = splitguess\n",
    "        return options\n",
    "\n",
    "    def manual_naming(self):\n",
    "        text = ['set first_name(, last_name)? for',self.file_name,'']\n",
    "        options = self.manual_name_options()\n",
    "        text.extend(list(options.values()))\n",
    "        text = '\\n'.join(text)\n",
    "        name = input(text + '\\n\\n')\n",
    "        if name == '':\n",
    "            return False\n",
    "        else:\n",
    "            if name == 'n':\n",
    "                self.author_name = options['no']\n",
    "            elif name == 'g' and 'guess' in options:\n",
    "#                 print('selected option:',options[3])\n",
    "                self.author_name = options['guess'][3:]\n",
    "            else:\n",
    "                self.author_name = name\n",
    "            self.auto_named = False\n",
    "            # keep auto_name_group so we see, if there was something before\n",
    "            self.manually_named = True\n",
    "            return True\n",
    "\n",
    "    def simple_manual_merge(self, other_desrc):\n",
    "        new_file_descr = copy(self)   \n",
    "        if other_desrc.manually_named and not new_file_descr.manually_named:\n",
    "            new_file_descr.manually_named = True\n",
    "            new_file_descr.author_name = other_desrc.author_name\n",
    "        return new_file_descr\n",
    "    \n",
    "class DescriptorCollection:\n",
    "    \"\"\"\n",
    "    File descriptors for a folder of files\n",
    "    \"\"\"\n",
    "    def __init__(self,folder_name,folder_path, dict_ = None):\n",
    "        self.folder_name = folder_name\n",
    "        self.folder_path = folder_path\n",
    "        self.file_descriptors = {}\n",
    "        \n",
    "        if dict_:\n",
    "            self.from_dict(dict_)\n",
    "\n",
    "    def to_dict(self):\n",
    "        dict_ = self.__dict__.copy()\n",
    "        dict_['file_descriptors'] = {file_descr: self.file_descriptors[file_descr].to_dict() for file_descr in self.file_descriptors}\n",
    "        return dict_\n",
    "            \n",
    "    def from_dict(self, dict_):\n",
    "        self.__dict__ = dict_\n",
    "        self.file_descriptors = {file_descr_name : FileDescriptor('',self.file_descriptors[file_descr_name]) \n",
    "                                 for file_descr_name in self.file_descriptors}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict())\n",
    "    \n",
    "    def short_description(self):\n",
    "        dict_ = self.to_dict().copy()\n",
    "        dict_['file_descriptors'] = len(dict_['file_descriptors'])\n",
    "        return json.dumps(dict_)\n",
    "    \n",
    "    def build(self, file_filter = None, file_name_processor= None):\n",
    "        \"\"\"\n",
    "        for initialisation:\n",
    "        builds a log dict for a list of file in a folder. \n",
    "        the actual selection of files can be filtered with a passed function\n",
    "        for each selected file the empty description is created\n",
    "        \"\"\"\n",
    "        for file_ in os.listdir(self.folder_path):\n",
    "            if not file_filter or file_filter(file_):\n",
    "                file_key = file_ \n",
    "                if file_name_processor:\n",
    "                    file_key = file_name_processor(file_)\n",
    "                self.file_descriptors[file_key] = FileDescriptor(file_)\n",
    "#         return log_files\n",
    "    \n",
    "    def get_descriptor(self, file_name_or_index):\n",
    "        if type(file_name_or_index) == str:\n",
    "            return self.file_descriptors[file_name_or_index]\n",
    "        elif type(file_name_or_index) == int:\n",
    "            return list(self.file_descriptors.values())[file_name_or_index]\n",
    "        \n",
    "    def auto_name_all(self, override_old_auto = False, override_manual = False, debug= False):\n",
    "        for file_descr in list(self.file_descriptors.values()):\n",
    "            file_descr.auto_name(override_old_auto, override_manual, debug)\n",
    "            \n",
    "    def info(self):\n",
    "        print('Collection:',self.folder_name)\n",
    "        print(len(self.file_descriptors), 'docs')\n",
    "        print(sum([1 for text_descr in list(self.file_descriptors.values()) if text_descr.auto_named]), 'auto named')\n",
    "        sum_man_named = sum([1 for text_descr in list(self.file_descriptors.values()) if text_descr.manually_named])\n",
    "        sum_assigned = sum([1 for text_descr in list(self.file_descriptors.values()) if text_descr.assigned_to])\n",
    "        print(sum_man_named,'/',sum_assigned, 'manually named/assigned')\n",
    "        \n",
    "        \n",
    "    def file_descr_list(self):\n",
    "        return list(self.file_descriptors.values())\n",
    "    \n",
    "    def get_all_missing(self):    \n",
    "        return [text_descr for text_descr in self.file_descr_list() if not text_descr.author_name]\n",
    "        \n",
    "    def get_all_assigned_to(self, name = None, only_missing = False):\n",
    "        return [text_descr for text_descr in list(self.file_descriptors.values()) \n",
    "                if text_descr.assigned_to == name  and not(only_missing and text_descr.manually_named)]\n",
    " \n",
    "    def merge(self, other_collection):\n",
    "        \"\"\"\n",
    "        merge in another collection. should be the same basis, just with different file_descriptior values:\n",
    "        manually assigned author names... basically\n",
    "        creates a NEW COLLECTION\n",
    "        Preference goes to auto_naming, if it doens't exist in the 2nd collection. that means the other has a smarter algo\n",
    "        \n",
    "        \"\"\"\n",
    "        # TODO\n",
    "#         for file_descr_name in self.file_descriptors:\n",
    "#             # file descriptor not in other collection? weird... ignore\n",
    "#             if file_descr_name not in other_collection:\n",
    "#                 print(file_descr, 'is not in the 2nd collection. not gonna take it')\n",
    "#             file_descr1 = self.file_descriptors[file_descr_name]\n",
    "#             file_descr2 = other_collection.file_descriptors[file_descr_name]\n",
    "#             new_file_descr = FileDescriptor(file_descr1.file_name)\n",
    "#             # we need to cover 4 cases. auto-auto, auto-man, man-auto, man-man, \n",
    "#             # if file_descr1.auto_named and not file_descr2.auto_named\n",
    "        \n",
    "            \n",
    "    def simple_manual_merge(self, other_collection):\n",
    "        \"\"\"\n",
    "        just slam the file_descr together to complete the authors.\n",
    "        assumption is that auto_naming is the same and just different assigned descriptors are merges\n",
    "        Returns a new log\n",
    "        \"\"\"\n",
    "        new_col_desrc = DescriptorCollection(self.folder_name, self.folder_path)\n",
    "        for file_descr_name in self.file_descriptors:\n",
    "            file_descr1 = self.file_descriptors[file_descr_name]\n",
    "            file_descr2 = other_collection.file_descriptors[file_descr_name]\n",
    "            new_file_descr = file_descr1.simple_manual_merge(file_descr2)\n",
    "            new_col_desrc.file_descriptors[file_descr_name] = new_file_descr \n",
    "        return new_col_desrc\n",
    "    \n",
    "    def get_all_auto_named(self):\n",
    "        return [file_descr for file_descr in self.file_descr_list() if file_descr.auto_named]\n",
    "    \n",
    "    def get_all_manualy_named(self):\n",
    "        return [file_descr for file_descr in self.file_descr_list() if file_descr.manually_named and file_descr.author_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part is simple.\n",
    "Initiate the description files for our corpus.\n",
    "\n",
    "This is only for initialisation. If it's done you can just **load a log file**...\n",
    "At the end we get a dict, where the keys are foldernames and the values are DescriptorCollections\n",
    "```\n",
    "{\n",
    "    folder_name: {\n",
    "        <DescriptorCollections>: as_json:\n",
    "        folder_name: <folder_name>\n",
    "        folder_path: <folder_path>,\n",
    "        log_files: <list of FileDescriptors>\n",
    "    }\n",
    "},\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# <<< 3/6\n",
    "\n",
    "def build_descr_folder(base_path, folder_names, file_filter, file_name_processor):\n",
    "    \"\"\"\n",
    "    build multiple folder in one base folder to a dict\n",
    "    {key: folder_name ; value: {path: folder_path, list of fileDescriptions}}\n",
    "    \"\"\"\n",
    "    descr_collections = []\n",
    "    for folder_name in folder_names:\n",
    "        descr_folder = DescriptorCollection(folder_name, base_path + folder_name)\n",
    "        descr_folder.build(file_filter, file_name_processor)\n",
    "        descr_collections.append(descr_folder)    \n",
    "    return {collection.folder_name : collection for collection in descr_collections} \n",
    "\n",
    "def load_descr_folder_from_dict(dict_):\n",
    "    log = {}\n",
    "    for col_folder in dict_:\n",
    "        log[col_folder] = DescriptorCollection(None, None, dict_[col_folder])\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some methods to initiate a set of collections, read and dump them to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <<< 4/6\n",
    "\n",
    "def init_log(base_path, file_filter = None, file_name_processor = None):\n",
    "    \"\"\"\n",
    "    initialises\n",
    "    \"\"\"\n",
    "    folder_names = [obj for obj in os.listdir(base_path) if os.path.isdir(base_path + obj)]\n",
    "    log = build_descr_folder(main_path, folder_names, file_filter, file_name_processor)\n",
    "  \n",
    "    # print(log_files)\n",
    "    total_size = 0\n",
    "    for folder in log:\n",
    "        print(folder)\n",
    "        print(len(log[folder].file_descriptors),'log files')\n",
    "        total_size += len(log[folder].file_descriptors)\n",
    "    print('TOTAL SIZE',total_size)\n",
    "    return log\n",
    "\n",
    "        \n",
    "def read_log(log_file_name):\n",
    "    try:\n",
    "        with codecs.open(log_file_name,encoding='utf-8') as fin:\n",
    "            log_dict = json.loads(fin.read())\n",
    "    except FileNotFoundError:\n",
    "        write_log_file()\n",
    "    return load_descr_folder_from_dict(log_dict)\n",
    "\n",
    "\n",
    "def write_log_file(log, log_file_name):\n",
    "    \"\"\"\n",
    "    log is a dict of collection. dump it to drive...\n",
    "    \"\"\"\n",
    "    dict_ = {col: log[col].to_dict() for col in log} \n",
    "    with codecs.open(log_file_name,'w', encoding='utf-8') as fout:\n",
    "        fout.write(json.dumps(dict_, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '../../../data/NAIL_DATAFIELD_txt/parsed_v3/'\n",
    "\n",
    "def valid_file_filter(file_name):\n",
    "    return '_valid' in file_name\n",
    "\n",
    "def valid_file_name_processor(file_name):\n",
    "    return file_name[:-len('_valid.txt')]\n",
    "\n",
    "log = init_log(main_path, valid_file_filter, valid_file_name_processor)\n",
    "write_log_file(log,'log.json')\n",
    "\n",
    "# now we can grab a file descriptor either by some index or by it's file name:\n",
    "file_descr = log['arts_arthistory_aesthetics'].get_descriptor(0)\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))\n",
    "file_descr = log['arts_arthistory_aesthetics'].get_descriptor('Batsford - Gwen.White-Perspective.A.Guide.For.Artists,.Architects.and.Designers')\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing read\n",
    "# log = read_log('log.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking a single file if it would find a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_descr.auto_name_check(debug = True)\n",
    "# that looks good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the auto naming function, which will if it finds a name and the deciscion tree rules are cool set the \"file description\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test auto_name\n",
    "file_descr.auto_name(debug= True)\n",
    "print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manual naming could work like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_descr.manual_naming()\n",
    "#print(json.dumps(file_descr.to_dict(), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we go through all files in bulk. Instead of `auto_name_check` we use `auto_name`,\n",
    "which will call `set_auto_name` in case we found something.\n",
    "The complete check also allowes us to assign a random 'person name' to each text document which has not been auto_named. At the end, we get an overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< 5/6\n",
    "\n",
    "def complete_check(dict_of_collections, assign_equally_to = None, \n",
    "                   override_old_auto = False, override_manual = False, debug= False):\n",
    "    \"\"\"\n",
    "    when assign_equally_to contains a list, it will randomly choose one for each file that is not\n",
    "    auto-named\n",
    "    \"\"\"\n",
    "    for collection in list(dict_of_collections.values()):\n",
    "        collection.auto_name_all()\n",
    "        for file_descr in list(collection.file_descriptors.values()):\n",
    "            if not file_descr.auto_named and assign_equally_to:\n",
    "                file_descr.assigned_to = choice(assign_equally_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_check(log,['M','R'])\n",
    "print()\n",
    "for col in log:\n",
    "    log[col].info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at all assigned descriptors of own_mixed_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[file_descr for file_descr in list(log['own_mixed_collection'].file_descriptors.values()) if file_descr.assigned_to]\n",
    "# we could also call `get_all_missing` which returns all file_descr. which don't have an author yet\n",
    "# log['own_mixed_collection'].get_all_missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nice... now lets get all of them assigned to 'R'. I added a function for that, to have it handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_to_R = log['own_mixed_collection'].get_all_assigned_to('R')\n",
    "assigned_to_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's manually name them and get the info of that collection again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_descr in assigned_to_R:\n",
    "    file_descr.manual_naming()\n",
    "    clear_output()\n",
    "print('cool all done')\n",
    "log['own_mixed_collection'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you tired you can write the log now. for later you can also just grab those, which are not set yet. \n",
    "The second parameter 'only_missing' default False does just that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_to_R = log['own_mixed_collection'].get_all_assigned_to('R', True)\n",
    "assigned_to_R\n",
    "# EMPTY SINCE R did all ot his files..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to merge 2 logs. Let's not rely on git with that... :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< 6/6\n",
    "\n",
    "def simple_manual_merge_logs(log1, log2):\n",
    "    final_log = {}\n",
    "    for col_name in log1:\n",
    "        if col_name in log2:\n",
    "            final_log[col_name] = log1[col_name].simple_manual_merge(log2[col_name]) \n",
    "        else:\n",
    "            print('collection', col_name,'is missing')\n",
    "    return final_log\n",
    "# simple_manual_merge_logs(log,log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the merge... \n",
    "a bit hacky...\n",
    "- initiate a second log `log2`, \n",
    "- do auto naming without assignments\n",
    "- copy the assignments of `own_mixed_collection` from `log` to `log2` \n",
    "- manualy name log2 `own_mixed_collection` for M\n",
    "- now `log` has all R manualy named and `log2` all Ms\n",
    "- merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still a bit strange...\n",
    "\n",
    "# initiate a second log\n",
    "log2 = init_log(main_path, valid_file_filter, valid_file_name_processor)\n",
    "# do auto naming without assignments\n",
    "complete_check(log2)\n",
    "\n",
    "# copy the assignments of own_mixed_collection from log to log2\n",
    "for file_descr in log['own_mixed_collection'].file_descriptors:\n",
    "   assigned_to = log['own_mixed_collection'].file_descriptors[file_descr].assigned_to\n",
    "   log2['own_mixed_collection'].file_descriptors[file_descr].assigned_to = assigned_to\n",
    "\n",
    "# manualy name log2 own_mixed_collection for M\n",
    "assigned_to_M = log2['own_mixed_collection'].get_all_assigned_to('M')\n",
    "print(assigned_to_M)\n",
    "for file_descr in assigned_to_M:\n",
    "    file_descr.manual_naming()\n",
    "    clear_output()\n",
    "\n",
    "log2['own_mixed_collection'].info()\n",
    "\n",
    "newLog = simple_manual_merge_logs(log,log2)\n",
    "newLog['own_mixed_collection'].info() \n",
    "newLog['own_mixed_collection'].get_all_manualy_named()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last final part!**\n",
    "*Run all the required 6 cells before*\n",
    "\n",
    "1. initiate or load\n",
    "\n",
    "2. load a second and merge it in\n",
    "\n",
    "3. run through all collections a manualy fill in missing file descriptions\n",
    "\n",
    "4. save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MAIN PROCESS!\n",
    "\n",
    "I_AM = 'R' # alternative 'M'\n",
    "\n",
    "main_path = '../../../data/NAIL_DATAFIELD_txt/parsed_v3/'\n",
    "\n",
    "def valid_file_filter(file_name):\n",
    "    return '_valid' in file_name\n",
    "\n",
    "def valid_file_name_processor(file_name):\n",
    "    return file_name[:-len('_valid.txt')]\n",
    "\n",
    "# 1. initiate or load\n",
    "# init\n",
    "# log = init_log(main_path, valid_file_filter, valid_file_name_processor)\n",
    "# complete_check(log,['M','R'])\n",
    "\n",
    "# load\n",
    "log = read_log('log.json')\n",
    "\n",
    "for col in list(log.values()):\n",
    "    col.info()\n",
    "    \n",
    "# 2. load a second and merge it in (if exists)\n",
    "if os.path.isfile('alt_log.json'):\n",
    "    alt_log = read_log('alt_log.json')\n",
    "    log = simple_manual_merge_logs(log,alt_log)\n",
    "\n",
    "# 3. run through all collections a manualy fill in missing file descriptions\n",
    "quit = False\n",
    "for collection in list(log.values()):\n",
    "    assigned_to_me = collection.get_all_assigned_to(I_AM, True)\n",
    "    for file_descr in assigned_to_me:\n",
    "        if not file_descr.manual_naming():\n",
    "            quit = True\n",
    "            break\n",
    "        clear_output()\n",
    "    if quit:\n",
    "        break\n",
    "        \n",
    "clear_output()\n",
    "\n",
    "for col in list(log.values()):\n",
    "    col.info()\n",
    "\n",
    "# 4. save it\n",
    "write_log_file(log,'log.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
